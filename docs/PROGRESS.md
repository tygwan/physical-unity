# Progress Tracker

## Project: Autonomous Driving ML Platform

**Focus**: Planning (RL/IL ëª¨ì…˜ í”Œë˜ë‹)

---

## Current Status

| Metric | Value |
|--------|-------|
| **Current Phase** | Phase 5 - Reinforcement Learning |
| **Current Training** | v12 Phase B (Overtake vs Follow Decision) |
| **Overall Progress** | 65% |
| **Architecture** | Tesla-style E2E (Camera â†’ Neural Net â†’ Control) |
| **Last Updated** | 2026-01-25 |

### v12 Overtaking Training Progress ğŸ”„

#### Phase A: ê¸°ë³¸ ì¶”ì›” í•™ìŠµ âœ… COMPLETED
- **Config**: `vehicle_ppo_v12_phaseA.yaml`
- **Steps**: 2M (ì™„ë£Œ)
- **Best Reward**: **+937** (1.37M step)
- **Final Reward**: +714.7
- **í•µì‹¬ ì„±ê³¼**: Speed penalty ë²„ê·¸ ìˆ˜ì • í›„ ì™„ë²½í•œ ì¶”ì›” í–‰ë™ í•™ìŠµ
- **Model**: `results/v12_phaseA_fixed/E2EDrivingAgent-1999953.onnx`

#### Phase B: ì¶”ì›” vs ë”°ë¼ê°€ê¸° íŒë‹¨ ğŸ”„ IN PROGRESS
- **Config**: `vehicle_ppo_v12_phaseB.yaml`
- **Initialize From**: Phase A best model
- **Goal**: NPC ì†ë„ì— ë”°ë¼ ì¶”ì›”/ë”°ë¼ê°€ê¸° ê²°ì • í•™ìŠµ
- **NPC Speed Curriculum**: 0.3 â†’ 0.5 â†’ 0.7 â†’ 0.9
- **Expected Steps**: 2M
- **Status**: í•™ìŠµ ì‹œì‘ë¨ (Unity Play ëŒ€ê¸°ì¤‘)

#### Phase C: ë³µì¡ í™˜ê²½ ì¼ë°˜í™” (ê³„íš)
- **Config**: `vehicle_ppo_v12_phaseC.yaml`
- **NPC Count**: 2-4ëŒ€
- **Speed Variation**: 0.15-0.3
- **Goal Distance**: 100m â†’ 160m â†’ 230m
- **Expected Steps**: 4M

### ì—°êµ¬ ê¸°ë°˜ ê°œì„  ê³„íš (RESEARCH-TRENDS-2024-2026)

| ê°œì„  ì‚¬í•­ | ì¶œì²˜ | Phase | ìš°ì„ ìˆœìœ„ |
|-----------|------|-------|----------|
| TTC Observation ì¶”ê°€ | Safe RL | 5.5 | HIGH |
| Network 512â†’1024 | Quick Win | 5.5 | MEDIUM |
| Teacher-Student Distillation | CuRLA | 6 | HIGH |
| GAIL í†µí•© | IL Research | 6 | HIGH |
| CMDP/Safe RL | LSTC | 6 | MEDIUM |
| Diffusion Planning | ICLR 2025 | 7 | LOW |

### Stage 4 Reward ì¬ì¡°ì • (v7â†’v8 ë³€ê²½ì‚¬í•­)

| í•­ëª© | v7 (ì´ì „) | v8 (í˜„ì¬) | ë³€ê²½ ì´ìœ  |
|------|-----------|-----------|-----------|
| collision | -10.0 | **-5.0** | PPO gradient instability ì™„í™” |
| nearCollision | -0.5/frame | **-1.5/sec** (Ã—deltaTime) | í”„ë ˆì„ ë¹„ë…ë¦½ â†’ rate-independent |
| off_road | -5.0/sec (ëˆ„ì ) | **-5.0 + EndEpisode** | -200 ëˆ„ì  ë°©ì§€, ì¦‰ì‹œ ì¢…ë£Œ |
| NPC curriculum | 0â†’2â†’4â†’6 | **0â†’1â†’2â†’4** (ì ì§„ì ) | ê¸‰ê²©í•œ ë‚œì´ë„ ì¦ê°€ ë°©ì§€ |
| NPC threshold | -2.0 (goalê³¼ ë™ì¼) | **-1.5, -1.0, 0.0** (ê°œë³„) | ë™ì‹œ ì§„í–‰ ë°©ì§€ |
| goal_distance | 50â†’120â†’230 | **50â†’100â†’160â†’230** | ì¤‘ê°„ ë‹¨ê³„ ì¶”ê°€ |
| max_steps | 5,000,000 | **8,000,000** | ìˆ˜ë ´ ì‹œê°„ í™•ë³´ |
| timeout_wait | 300s | **600s** | Unity ì‘ë‹µ ì‹œê°„ í™•ë³´ |

### Experiment Pipeline (Revised 2026-01-24)

```
Phase 5A: Vector-based RL (ë²¡í„° ê´€ì¸¡ ê¸°ë°˜)
  âœ… Stage 1: BC Baseline
  âœ… Stage 2: PPO Single Area (950K, Reward ~700)
  âœ… Stage 3: 16x Parallel PPO (1.66M, Reward ~750 ìˆ˜ë ´)
  ğŸ”„ Stage 4: ì†ë„ ì •ì±… (v8, 3.07M/8M steps)          â† í˜„ì¬ ì§„í–‰ ì¤‘
  â³ Stage 5: Multi-Lane + ì°¨ì„  ì •ì±…
  â³ Stage 6: ë„ë¡œ ë„¤íŠ¸ì›Œí¬ + êµì°¨ë¡œ + ê²½ë¡œ ì¶”ì¢… â˜…

Phase 5B: Vision-based RL (ì¹´ë©”ë¼ ì…ë ¥)
  â³ Stage 7: Camera Visual Observation (nature_cnn)
  â³ Stage 8: Euro NCAP í‰ê°€ (ELK/LKA) + ì‹ í˜¸ë“± ì¸ì‹

Phase 5C: Hybrid & Advanced
  â³ Stage 9: Expert ë…¹í™” â†’ GAIL/Hybrid
  â³ Stage 10: Full E2E (BEV + Temporal)
```

### Stage 4 ì™„ë£Œ í›„ ê³„íš
1. **32 Training Areas í™•ì¥** - ë²¡í„° ì „ìš© ê´€ì¸¡ ì‹œ 32ê°œ ë³‘ë ¬ í•™ìŠµ ê°€ëŠ¥ (VRAM ~8GB)
2. **SAC ë¹„êµ ì‹¤í—˜** - ë™ì¼ í™˜ê²½ì—ì„œ PPO vs SAC ì•Œê³ ë¦¬ì¦˜ ê²€ì¦
3. **ì¹´ë©”ë¼/LiDAR ë³‘ë ¬ ì œí•œ** - ì„¼ì„œ ì¶”ê°€ ì‹œ 8-16 Areasë¡œ ì¶•ì†Œ í•„ìš” (VRAM ì œì•½)

### í–¥í›„ ë³‘ë ¬ Training Areas ê³„íš
```
í˜„ì¬: 16 Areas (Vector-only) â†’ GPU 11%, VRAM 3.6GB
ë‹¤ìŒ: 32 Areas (Vector-only) â†’ GPU ~22%, VRAM ~8GB  â† Stage 4 ì™„ë£Œ í›„ ì ìš©
ì¹´ë©”ë¼: 8-16 Areas (Camera 84x84) â†’ VRAM 8-12GB     â† Stage 7ì—ì„œ ì ìš©
LiDAR:  8 Areas (LiDAR+Camera) â†’ VRAM 12-16GB       â† Phase 6ì—ì„œ ê²€í† 
```

### ì‹ í˜¸ë“± ì¸ì‹ í•™ìŠµ ê³„íš (Phase 6 ë²”ìœ„)
- **í˜„ì¬ Stage 4**: ì†ë„ ì œí•œë§Œ (í‘œì§€íŒ = ground truth observation)
- **Stage 7-8**: ì¹´ë©”ë¼ ì…ë ¥ + CNN encoderë¡œ ì‹œê°ì  ì¸ì‹
- **Phase 6**: ì‹ í˜¸ë“± ì¸ì‹ (ì /ë…¹/í™©) + ì •ì§€/ì¶œë°œ ì •ì±…
  - Camera observationìœ¼ë¡œ ì‹ í˜¸ë“± ìƒ‰ìƒ ì¸ì‹
  - traffic_light reward: ì ìƒ‰ ì •ì§€(+0.5), ì ìƒ‰ ìœ„ë°˜(-5.0)
  - êµì°¨ë¡œ + ì‹ í˜¸ì²´ê³„ í†µí•© (Stage 6 ë„ë¡œ ë„¤íŠ¸ì›Œí¬ ì´í›„)

### í¬íŠ¸ ì¶©ëŒ í•´ê²°ë²•
ì´ì „ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ê°€ í¬íŠ¸ 5004ë¥¼ ì ìœ  ì¤‘ì¼ ìˆ˜ ìˆìŒ:
```bash
netstat -ano | findstr 5004    # PID í™•ì¸
taskkill /PID <PID> /F         # í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ (cmdì—ì„œ ì‹¤í–‰)
```
ë˜ëŠ” Unity Play ëª¨ë“œ ì¤‘ì§€ â†’ ì¬ì‹œì‘ìœ¼ë¡œ í•´ê²°

---

## Phase Overview (7 Phases) - Tesla-style E2E Architecture

| Phase | Name | Duration | Status | Progress | Deliverable |
|-------|------|----------|--------|----------|-------------|
| **Phase 1** | Foundation & Architecture | 2-3ì£¼ | âœ… Complete | 100% | Unity + ML-Agents + ROS2 + Sensors |
| **Phase 2** | Data Infrastructure | 3-4ì£¼ | âœ… Complete | 90% | nuPlan íŒŒì´í”„ë¼ì¸ (loader/processor/augmentation) |
| **Phase 3** | E2E Model Architecture | 3-4ì£¼ | âœ… Complete | 100% | PyTorch E2E ëª¨ë¸ (RegNetâ†’Planning) |
| **Phase 4** | Imitation Learning | 3-4ì£¼ | âœ… Complete | 100% | BC/GAIL í•™ìŠµ íŒŒì´í”„ë¼ì¸ |
| **Phase 5** | Reinforcement Learning â­ | 6-10ì£¼ | ğŸ”„ In Progress | 40% | Stage 4 ì§„í–‰ ì¤‘ (v8 3.07M/8M, NPC+ì†ë„ì •ì±… í•™ìŠµ) |
| **Phase 6** | Hybrid & Deployment | 3-4ì£¼ | â³ Pending | 0% | ILâ†’RL + Sentis + ROS2 ë°°í¬ |
| **Phase 7** | Advanced Topics | Ongoing | â³ Pending | 0% | World Model, Sim-to-Real |

### Architecture Decision: Tesla-style E2E

```
ê¸°ì¡´ ê³„íš (Modular):
  Perception â†’ Prediction â†’ Planning â†’ Control (ê°ê° ë…ë¦½)

ìƒˆ ê³„íš (E2E):
  Camera Images â†’ [Single Neural Network] â†’ steering + acceleration
  (Tesla FSD v12+ ë°©ì‹: ëª¨ë“  ëª¨ë“ˆì´ í•˜ë‚˜ì˜ ë„¤íŠ¸ì›Œí¬ë¡œ í†µí•©)
```

**ê·¼ê±°**: Tesla FSD ì¡°ì‚¬ ê²°ê³¼, E2E ì ‘ê·¼ë²•ì´ ëª¨ë“ˆì‹ ëŒ€ë¹„:
- ì½”ë“œ ë³µì¡ë„ 250x ê°ì†Œ (500kâ†’2k lines)
- ì—ëŸ¬ ì „íŒŒ ì œê±° (72.7% â†’ unified optimization)
- í•™ìŠµ ì†ë„ í–¥ìƒ (ë‹¨ì¼ backprop)
- ì¼ë°˜í™” ì„±ëŠ¥ ìš°ìˆ˜

---

## Milestone Tracker

| Milestone | Target | Status | Actual | Deliverable |
|-----------|--------|--------|--------|-------------|
| M1: í™˜ê²½ ì™„ë£Œ | Week 3 | âœ… Complete | Week 4 | Unity+ML-Agents+ROS2 |
| M2: ë°ì´í„° íŒŒì´í”„ë¼ì¸ | Week 7 | âœ… Complete | Week 5 | nuPlan loader+processor |
| M3: E2E ëª¨ë¸ êµ¬í˜„ | Week 11 | âœ… Complete | Week 8 | PyTorch E2E model (.pt) |
| M4: IL í•™ìŠµ ì™„ë£Œ | Week 15 | âœ… Complete | Week 8 | BC/GAIL training pipeline |
| M5: RL í•™ìŠµ ì™„ë£Œ | Week 27 | ğŸ”„ In Progress | - | Stage 3/10 ì™„ë£Œ. ê²½ë¡œì¶”ì¢…+ì¹´ë©”ë¼+E2E ì§„í–‰ ì¤‘ |
| M6: ë°°í¬ ì™„ë£Œ | Week 25 | â³ Pending | - | Sentis .onnx + ROS2 |

---

## Phase 1: Foundation & Architecture (Current)

### Objectives
- Windows ë„¤ì´í‹°ë¸Œ í™˜ê²½ êµ¬ì¶•
- Unity-ROS2 ì—°ë™ í™•ë¦½
- ML-Agents RL í•™ìŠµ í™˜ê²½ êµ¬ì¶•
- ê¸°ë³¸ ì£¼í–‰ í™˜ê²½ Scene ìƒì„±

### Task Breakdown

| ID | Task | Priority | Status | Notes |
|----|------|----------|--------|-------|
| P1-01 | ROS2 Humble ì„¤ì¹˜ | High | âœ… Complete | WSL2 (ì´ˆê¸° ì„¤ì •, í˜„ì¬ ML-Agents ì‚¬ìš©) |
| P1-02 | Unity Robotics Hub í…ŒìŠ¤íŠ¸ | High | âœ… Complete | ROS-TCP-Connector ì—°ë™ |
| P1-03 | ros2-for-unity í…ŒìŠ¤íŠ¸ | High | â³ Pending | (ì„ íƒì‚¬í•­) |
| P1-04 | ROS2-Unity ì—°ê²° í™•ì¸ | High | âœ… Complete | TCP í†µì‹  ì„±ê³µ |
| P1-05 | ML-Agents 4.0 RL í™˜ê²½ êµ¬ì¶• | High | âœ… Complete | Unity 6 + ML-Agents 4.0.1 |
| P1-06 | ê¸°ë³¸ ì£¼í–‰ í™˜ê²½ Scene ìƒì„± | High | âœ… Complete | DrivingScene.unity |
| P1-07 | ì„¼ì„œ í†µí•© (LiDAR/Camera) | Medium | âœ… Complete | CameraSensor, LiDARSensor |
| P1-08 | ì‹¤í—˜ ì¶”ì  ì„¤ì • (MLflow/W&B) | Medium | âœ… Complete | experiment_tracker.py |

### Completed âœ…
- [x] í”„ë¡œì íŠ¸ ì €ì¥ì†Œ ì´ˆê¸°í™”
- [x] ë””ë ‰í† ë¦¬ êµ¬ì¡° ì„¤ê³„ (AD í”Œë«í¼ ìš©ë„ë¡œ ì¬êµ¬ì„±)
- [x] README.md ì‘ì„±
- [x] ê¸°ìˆ  ë¬¸ì„œ ì‘ì„± (PRD, TECH-SPEC)
- [x] cc-initializer ì„¤ì • ì—…ë°ì´íŠ¸
- [x] **Unity 6 (6000.3.4f1) í™˜ê²½ êµ¬ì¶•**
- [x] **ML-Agents 4.0.1 ì„¤ì¹˜ ë° ì„¤ì •**
- [x] **Unity Sentis 2.4.1 ì„¤ì¹˜**
- [x] **Python mlagents 1.1.0 + PyTorch 2.3.1 ì„¤ì¹˜**
- [x] **3DBall í•™ìŠµ í…ŒìŠ¤íŠ¸ ì„±ê³µ (500K steps, Reward 100)**
- [x] **ONNX ëª¨ë¸ Export ë° Inference í™•ì¸**
- [x] **WSL2 + ROS2 Humble ì„¤ì¹˜** *(ì´ˆê¸° ì„¤ì •, í˜„ì¬ ML-Agents ì§ì ‘ í†µì‹  ì‚¬ìš©)*
- [x] **ROS-TCP-Endpoint ë¹Œë“œ**
- [x] **Unity ROS-TCP-Connector ì„¤ì¹˜**
- [x] **ROS2 â†” Unity ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ**
- [x] **ê¸°ë³¸ ì£¼í–‰ Scene (DrivingScene) ìƒì„±**
- [x] **VehicleAgent.cs ìƒì„±** (ML-Agents ê¸°ë°˜)
- [x] **SimpleVehicleController.cs ìƒì„±** (í‚¤ë³´ë“œ í…ŒìŠ¤íŠ¸ìš©)
- [x] **í‚¤ë³´ë“œ ì£¼í–‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ** (W/A/S/D)
- [x] **VehicleROSBridge.cs ìƒì„±** (ROS2 Pub/Sub)
- [x] **ROS2 Topic êµ¬í˜„** (/vehicle/odom, /vehicle/pose, /vehicle/cmd_vel)
- [x] **CameraSensor.cs ìƒì„±** (VLAìš© ì´ë¯¸ì§€ ìº¡ì²˜)
- [x] **LiDARSensor.cs ìƒì„±** (í¬ì¸íŠ¸í´ë¼ìš°ë“œ ë ˆì´ìºìŠ¤íŒ…)
- [x] **ì„¼ì„œ ROS2 Publish** (/vehicle/camera/image_raw, /vehicle/lidar/points)
- [x] **ì‹¤í—˜ ì¶”ì  ì„¤ì •** (MLflow/W&B integration)

### In Progress ğŸ”„
*Phase 1 ì™„ë£Œ - Phase 2ë¡œ ì§„í–‰*

### Blocked ğŸš§
*í˜„ì¬ ë¸”ë¡œì»¤ ì—†ìŒ*

---

## Phase 2: Data Infrastructure âœ…

### Status: 90% Complete

### Completed Tasks
| ID | Task | Status | File |
|----|------|--------|------|
| P2-01 | nuPlan í™˜ê²½ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ | âœ… | `python/scripts/setup_nuplan.py` |
| P2-02 | nuPlan ë°ì´í„° ë¡œë” | âœ… | `python/src/data/nuplan_loader.py` |
| P2-03 | ì‹œë‚˜ë¦¬ì˜¤ ì „ì²˜ë¦¬ê¸° (PlanningProcessor) | âœ… | `python/src/data/processor.py` |
| P2-04 | ë°ì´í„° ì¦ê°• (6 techniques) | âœ… | `python/src/data/augmentation.py` |
| P2-05 | ì‹œê°í™” ë„êµ¬ (BEV plot) | âœ… | `python/src/data/visualizer.py` |
| P2-06 | Train/Val/Test ë¶„í•  | âœ… | `python/src/data/splitter.py` |
| P2-07 | Waymo Motion ë¡œë” | â³ Deferred | ìš°ì„ ìˆœìœ„ ë‚®ìŒ |

### Data Format (Unified Scenario)
```python
Scenario:
  ego_trajectory: [T, 7]  # x, y, heading, vx, vy, ax, ay
  agents: List[AgentTrack]  # ì£¼ë³€ ì°¨ëŸ‰
  map_features: Dict        # ë„ë¡œ ì •ë³´
  traffic_lights: List      # ì‹ í˜¸ë“± ìƒíƒœ

Observation (238D):
  ego_state: 8D + ego_history: 40D + agents: 160D + route: 30D

Action (2D):
  acceleration: [-4.0, +2.0] m/sÂ²
  steering: [-0.5, +0.5] rad
```

---

## Phase 3: E2E Model Architecture ğŸ”„ (Current)

### Objectives
Tesla FSD v12+ ìŠ¤íƒ€ì¼ E2E ì‹ ê²½ë§ êµ¬í˜„

### Architecture Overview
```
Input Layer
â”œâ”€â”€ Camera Images: [B, 8, 3, 768, 576] (8 cameras)
â”œâ”€â”€ Ego State: [B, 8] (position, velocity, heading, acceleration)
â”œâ”€â”€ Route Info: [B, 30] (waypoints)
â””â”€â”€ Temporal History: [B, 10, ...] (10 frames)
        |
        v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3-1. Backbone: RegNet                        â”‚
â”‚      Multi-scale features P1-P5              â”‚
â”‚      Output: [B, 512, 10, 8]                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3-2. Neck: BiFPN                             â”‚
â”‚      Cross-scale fusion (6 layers)           â”‚
â”‚      Output: [B, 256, 40, 30]               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3-3. Occupancy Network                       â”‚
â”‚      2D features â†’ 3D voxel grid            â”‚
â”‚      Output: [B, 100, 100, 4] (occupied?)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3-4. BEV Former                              â”‚
â”‚      Multi-camera â†’ BEV (Transformer)        â”‚
â”‚      Output: [B, 100, 100, 256]             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3-5. Temporal Fusion                         â”‚
â”‚      LSTM + Transformer (10 frames)          â”‚
â”‚      Output: [B, 256] context vector         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3-6. Planning Network                        â”‚
â”‚      Features â†’ Trajectory â†’ Control         â”‚
â”‚      Output: steering, acceleration          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3-7. E2E Integration                         â”‚
â”‚      All modules unified, single forward()   â”‚
â”‚      Export: .pt â†’ .onnx â†’ Sentis            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Task Breakdown

| ID | Task | Priority | Status | File Path |
|----|------|----------|--------|-----------|
| P3-01 | RegNet Backbone | High | â³ | `python/src/models/backbone/regnet.py` |
| P3-02 | BiFPN Neck | High | â³ | `python/src/models/neck/bifpn.py` |
| P3-03 | Occupancy Network | High | â³ | `python/src/models/perception/occupancy.py` |
| P3-04 | BEV Former | High | â³ | `python/src/models/perception/bev_former.py` |
| P3-05 | Temporal Fusion | Medium | â³ | `python/src/models/temporal/fusion.py` |
| P3-06 | Planning Network | High | â³ | `python/src/models/planning/planner.py` |
| P3-07 | E2E í†µí•© ëª¨ë¸ | High | â³ | `python/src/models/e2e_model.py` |
| P3-08 | ëª¨ë¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ | Medium | â³ | `python/tests/test_models.py` |
| P3-09 | ONNX Export ê²€ì¦ | Medium | â³ | `python/scripts/export_onnx.py` |

### Module Specifications

#### P3-01: RegNet Backbone
```python
Input:  [B, 3, H, W] per camera (or [B, 8, 3, H, W] concatenated)
Output: Multi-scale features
  P1: [B, 32, H/4, W/4]    # High-res details
  P2: [B, 64, H/8, W/8]
  P3: [B, 128, H/16, W/16]
  P4: [B, 256, H/32, W/32]
  P5: [B, 512, H/64, W/64]  # Global semantic

Config:
  depth: 50 (ResNet-50 scale, í™•ì¥ ê°€ëŠ¥)
  width_multiplier: 1.0
  group_width: 32
```

#### P3-02: BiFPN Neck
```python
Input:  P1-P5 multi-scale features
Output: Enhanced P3 features [B, 256, H/16, W/16]

Config:
  num_layers: 3-6
  channels: 256
  attention_type: "fast_attention"
```

#### P3-03: Occupancy Network
```python
Input:  BEV features [B, 256, 100, 100]
Output:
  occupancy: [B, 100, 100, 4]  # 100m x 100m x 4 height levels
  flow: [B, 100, 100, 2]       # vx, vy per cell

Resolution: 1m per cell
Height levels: 0-1m, 1-2m, 2-3m, 3-4m
```

#### P3-04: BEV Former
```python
Input:  8 camera features + camera matrices
Output: BEV features [B, 100, 100, 256]

Config:
  num_queries: 10000 (100x100 grid)
  num_heads: 8
  num_layers: 6
  d_model: 256
```

#### P3-05: Temporal Fusion
```python
Input:  Feature sequence [T=10, B, 256]
Output: Temporal context [B, 256]

Config:
  method: "transformer"  # or "lstm", "conv3d"
  num_frames: 10
  num_layers: 3
```

#### P3-06: Planning Network
```python
Input:
  occupancy: [B, 100, 100, 4]
  bev_features: [B, 100, 100, 256]
  temporal_context: [B, 256]
  ego_state: [B, 8]
  route_info: [B, 30]

Output:
  steering: [-0.5, +0.5] rad
  acceleration: [-4.0, +2.0] m/s^2
  trajectory: [B, 30, 3]  # 30 timesteps x (x, y, heading)
  confidence: [B, 6]      # 6 trajectory candidates

Architecture:
  - Multi-head attention fusion
  - 6 trajectory candidates generation
  - Confidence scoring + weighted selection
  - Final control output
```

#### P3-07: E2E Integration
```python
class E2EDrivingModel(nn.Module):
    """
    Tesla-style End-to-End Driving Model
    Input: cameras + ego_state + route
    Output: steering + acceleration
    """
    def __init__(self, config):
        self.backbone = RegNet(config.backbone)
        self.neck = BiFPN(config.neck)
        self.occupancy = OccupancyNetwork(config.occupancy)
        self.bev_former = BEVFormer(config.bev_former)
        self.temporal = TemporalFusion(config.temporal)
        self.planner = PlanningNetwork(config.planning)

    def forward(self, cameras, ego_state, route, camera_matrices):
        features = self.backbone(cameras)
        features = self.neck(features)
        bev = self.bev_former(features, camera_matrices)
        occ = self.occupancy(bev)
        temporal = self.temporal(bev)
        return self.planner(occ, bev, temporal, ego_state, route)
```

### Simplified Start Strategy
> ì²˜ìŒë¶€í„° ì „ì²´ ëª¨ë¸ì„ êµ¬í˜„í•˜ë©´ ë””ë²„ê¹…ì´ ì–´ë ¤ì›€.
> ë‹¨ê³„ì ìœ¼ë¡œ ë³µì¡ë„ë¥¼ ë†’ì´ëŠ” ì „ëµ:

```
Level 1 (MVP): MLP Planner only
  Input: 238D observation vector (ego+agents+route)
  Network: MLP (256â†’256â†’256â†’2)
  Output: steering, acceleration
  â†’ ë¹ ë¥´ê²Œ IL/RL íŒŒì´í”„ë¼ì¸ ê²€ì¦

Level 2: + Backbone
  Input: Camera images
  Network: ResNet-18 â†’ MLP â†’ control
  â†’ ì´ë¯¸ì§€ ì…ë ¥ ê²€ì¦

Level 3: + BEV + Occupancy
  Network: RegNet â†’ BiFPN â†’ BEV â†’ Planner
  â†’ ê³µê°„ ì´í•´ ì¶”ê°€

Level 4: + Temporal
  Network: Full E2E (RegNetâ†’BiFPNâ†’BEVâ†’Temporalâ†’Planner)
  â†’ ì‹œê°„ ì •ë³´ ì¶”ê°€ (ìµœì¢… ëª¨ë¸)
```

---

## Phase 4: Imitation Learning (IL)

### Objectives
nuPlan Expert ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ E2E ëª¨ë¸ í•™ìŠµ

### Task Breakdown

| ID | Task | Priority | Status |
|----|------|----------|--------|
| P4-01 | Behavioral Cloning í•™ìŠµê¸° | High | â³ |
| P4-02 | BC Loss ì„¤ê³„ (MSE + auxiliary) | High | â³ |
| P4-03 | DataLoader ì—°ë™ (PlanningDataset) | High | â³ |
| P4-04 | í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ (train_il.py) | High | â³ |
| P4-05 | ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ (validate_il.py) | Medium | â³ |
| P4-06 | GAIL êµ¬í˜„ | Medium | â³ |
| P4-07 | DAgger êµ¬í˜„ | Low | â³ |
| P4-08 | ì„±ëŠ¥ í‰ê°€ ë° ë¹„êµ | Medium | â³ |

### Training Configuration
```yaml
# Behavioral Cloning
optimizer: AdamW
lr: 3e-4
lr_scheduler: CosineAnnealing
batch_size: 256
epochs: 100
loss:
  steering_weight: 0.4
  acceleration_weight: 0.3
  trajectory_weight: 0.2
  auxiliary_weight: 0.1  # occupancy, lane prediction
early_stopping: patience=10
```

### IL Loss Design
```python
L_total = (
    w_steer * MSE(pred_steer, expert_steer) +
    w_accel * MSE(pred_accel, expert_accel) +
    w_traj  * MSE(pred_trajectory, expert_trajectory) +
    w_aux   * (BCE(pred_occupancy, gt_occupancy) +
               CE(pred_lanes, gt_lanes))
)
```

### Success Criteria (IL Phase)
| Metric | Target |
|--------|--------|
| Steering MSE | < 0.01 rad |
| Acceleration MSE | < 0.5 m/s^2 |
| Trajectory ADE | < 2.0m (6sec) |
| Collision Rate (sim) | < 15% |

---

## Phase 5: Reinforcement Learning (RL) â­

### Objectives
Unity ML-Agents í™˜ê²½ì—ì„œ RLë¡œ Planner ìµœì í™” â†’ ê²½ë¡œ ì¶”ì¢… â†’ ì¹´ë©”ë¼ ì…ë ¥ â†’ E2E í†µí•©

### Stage Progress

| Stage | Name | Status | Result |
|-------|------|--------|--------|
| 1 | BC Baseline | âœ… | Expert ë°ì´í„° í•™ìŠµ ì™„ë£Œ |
| 2 | PPO Single Area | âœ… | 950K steps, Reward ~700 |
| 3 | 16x Parallel PPO | âœ… | 1.66M steps, Reward ~750 ìˆ˜ë ´ |
| 4 | ì†ë„ ì •ì±… | ğŸ”„ | v8: 3.07M/8M, NPC+ì†ë„, Best +2.46 |
| 5 | Multi-Lane + ì°¨ì„  | â³ | 5ì¢… ì°¨ì„  ë§ˆí‚¹ + ì •ì±… |
| 6 | ë„ë¡œ ë„¤íŠ¸ì›Œí¬ + Navigation | â³ | êµì°¨ë¡œ + ê²½ë¡œ ì¶”ì¢… â˜… |
| 7 | Camera Visual Obs | â³ | CameraSensor + CNN encoder |
| 8 | Euro NCAP í‰ê°€ + ì‹ í˜¸ë“± | â³ | ELK/LKA + ì‹ í˜¸ ì¸ì‹ |
| 9 | GAIL + Hybrid | â³ | ILâ†’RL ê²°í•© |
| 10 | Full E2E + Ablation | â³ | BEV + Temporal í†µí•© |

### Training Progress (PPO v1) - 87K Steps (êµ¬ë²„ì „, ë¬¼ë¦¬ ë²„ê·¸ ìˆìŒ)
```
Step 5K:  Reward -6.061 (initial random policy)
Step 87K: Reward -4.932 (ì°¨ëŸ‰ ì›€ì§ì´ì§€ ì•ŠìŒ - ë¬¼ë¦¬ ë§ˆì°° ë²„ê·¸)
ì›ì¸: PhysX ë§ˆì°°ë ¥ì´ êµ¬ë™ë ¥ë³´ë‹¤ ì»¤ì„œ ì°¨ëŸ‰ ì •ì§€ ìƒíƒœ
```

### Training Progress (Curriculum PPO v5) - 950K+ Steps âœ… ì„±ê³µ!
```
=== Lesson 0: No Traffic, 50m Goal ===
Step   5K: Reward -18.3 (random exploration, ì°¨ëŸ‰ ì›€ì§ì„ í™•ì¸!)
Step  45K: Reward  -9.7 (ë¹ ë¥¸ ê°œì„ )
Step  90K: Reward +22.0 â†’ [Curriculum Advanced!]

=== Lesson 1: 2 NPCs, 120m Goal ===
Step 110K: Reward +35.0 (êµí†µ íšŒí”¼ í•™ìŠµ)
Step 170K: Reward +137  â†’ [Curriculum Advanced!]

=== Lesson 2: 4 NPCs, 230m Goal ===
Step 250K: Reward +223 (Near Mastery)
Step 395K: Reward +445 (Peak) â†’ [Curriculum Advanced!]

=== Lesson 3: 6 NPCs, 230m Goal (Full Traffic) ===
Step 465K: Reward +454 (6 NPCs ì ì‘ ì‹œì‘)
Step 545K: Reward +591 (ì•ˆì •ì  Std=29)
Step 675K: Reward +656 (Std=27, ê·¹ë„ë¡œ ì•ˆì •ì )
Step 695K: Reward +689 (Std=14, ìµœê³  ì•ˆì •ì„±)
Step 840K: Reward +696 (ê³ ìˆ˜ì¤€ ìœ ì§€)
Step 925K: Reward +697 (Plateau ë„ë‹¬)
Step 950K: Reward +618 (í•™ìŠµ ì§„í–‰ ì¤‘...)

500K Checkpoint: E2EDrivingAgent-499836.onnx
289K Checkpoint: models/planning/E2EDrivingAgent_curriculum_v5_289k.onnx
```

### Training Progress (16x Parallel PPO v6) - 1.66M Steps âœ… ìˆ˜ë ´!
```
Config: vehicle_ppo_curriculum_parallel.yaml
  batch=4096, buffer=40960, threaded=false, device=cuda
  16 Training Areas, 92K steps/min (4.6x ê°€ì†)

=== Lesson 0â†’3 ì „í™˜: 2.5ë¶„ ë§Œì— Full Traffic ì§„ì… ===
Step   10K: Reward  -19.2 (random)
Step  160K: Reward   +1.4 â†’ [Lesson1: 2 NPCs, 120m]
Step  230K: Reward  +34.9 â†’ [Lesson2: 4 NPCs, 230m]
Step  310K: Reward  +77.2 â†’ [Lesson3: 6 NPCs, 230m]

=== Lesson 3 ìˆ˜ë ´ ê³¼ì • ===
Step  500K: Reward +147   (Checkpoint saved)
Step 1000K: Reward +463   (Checkpoint saved)
Step 1300K: Reward +697   (ì•ˆì •í™”)
Step 1500K: Reward +706   (Checkpoint saved)
Step 1520K: Reward +748.6 â˜… Peak (Std=10.7, ê·¹ë„ë¡œ ì•ˆì •)
Step 1660K: Reward +716   (í•™ìŠµ ì¤‘ë‹¨ - ìˆ˜ë ´ í™•ì¸)

Checkpoints: results/curriculum_v6_parallel/E2EDrivingAgent/
  - E2EDrivingAgent-499849.onnx
  - E2EDrivingAgent-999809.onnx
  - E2EDrivingAgent-1499993.onnx

í•µì‹¬ ìˆ˜ì •ì‚¬í•­:
- ë¬¼ë¦¬ì—”ì§„: ForceMode â†’ ë‚´ë¶€ ì†ë„ ì¶”ì  + rb.linearVelocity ì§ì ‘ ì„¤ì •
- ì¤‘ë ¥/ë§ˆì°° ì œê±°: useGravity=false, PhysicsMaterial(friction=0)
- FreezePositionY: ì°¨ëŸ‰ Yì¶• ê³ ì •
- SimpleVehicleController ë¹„í™œì„±í™”
```

### Experiment Pipeline (Revised 2026-01-24)
```
Phase 5A: Vector-based RL (ì •ì±… ê²€ì¦)
  1. âœ… Behavioral Cloning (BC)        â†’ python/src/training/train_il.py
  2. âœ… Pure RL (PPO Single)           â†’ curriculum_v5: 950K steps, Reward ~700
  3. âœ… 16x Parallel PPO               â†’ curriculum_v6_parallel: 1.66M, Reward ~750 ìˆ˜ë ´
  4. ğŸ”„ ì†ë„ ì •ì±… (v8)                 â†’ 3.07M/8M, NPC+ì†ë„, Best +2.46
  5. â³ Multi-Lane + ì°¨ì„  ì •ì±…          â†’ 5ì¢… ë§ˆí‚¹, Raycast ê°ì§€, ìœ„ë°˜ íŒ¨ë„í‹°
  6. â³ ë„ë¡œ ë„¤íŠ¸ì›Œí¬ + Navigation â˜…    â†’ êµì°¨ë¡œ(T/ì‹­ì) + ê²½ë¡œ ì¶”ì¢… + A* planner

Phase 5B: Vision-based RL (ì¹´ë©”ë¼ ì¶”ê°€)
  7. â³ Camera Visual Observation       â†’ CameraSensor + nature_cnn/resnet encoder
  8. â³ Euro NCAP í‰ê°€ + ì‹ í˜¸ë“± ì¸ì‹    â†’ ELK/LKA + ì¹´ë©”ë¼ ì‹ í˜¸ì²´ê³„ í•™ìŠµ

Phase 5C: Hybrid & Advanced (E2E í†µí•©)
  9. â³ Expert ë…¹í™” â†’ GAIL/Hybrid      â†’ ì¹´ë©”ë¼ ê¸°ë°˜ ì‹œì—°, vehicle_gail.yaml
  10. â³ Full E2E + Ablation            â†’ BEV + Temporal + Planning í†µí•©

ì›ì¹™: ë²¡í„° ê¸°ë°˜ ì •ì±… ê²€ì¦ â†’ ì¹´ë©”ë¼ â†’ E2E (ë¹„ì „/ì •ì±… ë¬¸ì œ ë¶„ë¦¬)
Stage 4 ì´í›„: 32 Areas í™•ì¥ ì ìš© (Vector-only), ì„¼ì„œ ì¶”ê°€ ì‹œ 8-16 Areas
```

### ë³‘ë ¬ Training Areas ê³„íš (GPU í™œìš© ê·¹ëŒ€í™”)
```
=== í˜„ì¬ (Stage 4): 16 Training Areas ===
  - GPU: RTX 4090, ~11% í™œìš©, 3.6GB VRAM
  - ì†ë„: ~92K steps/min
  - í•™ìŠµ ì‹œê°„: 1M steps ì•½ 10ë¶„ (NPC+ì†ë„ í¬í•¨)

=== ë‹¤ìŒ (Stage 4 ì™„ë£Œ í›„): 32 Training Areas ===
  - ì ìš© ì¡°ê±´: Vector-only observation (242D)
  - ì˜ˆìƒ VRAM: ~8GB / 24GB
  - ì˜ˆìƒ ì†ë„: ~160K steps/min (1.7x ì¶”ê°€ ê°€ì†)
  - batch_size: 8192, buffer_size: 81920
  - ë ˆì´ì•„ì›ƒ: 8Ã—4 ê·¸ë¦¬ë“œ, 100m ê°„ê²©

=== Stage 7 (Camera ì¶”ê°€): 8-16 Training Areas ===
  - Camera 84x84 RGB â†’ ë Œë”ë§ ë¶€í•˜ ì¦ê°€
  - ì˜ˆìƒ VRAM: 8-12GB (16 areas) / 12-16GB (8 areas + LiDAR)
  - batch_size: 2048-4096 (ë©”ëª¨ë¦¬ ì œì•½)
  - íš¨ê³¼: ì¹´ë©”ë¼ ë Œë”ë§ì´ ë³‘ëª© â†’ GPU í™œìš©ë¥  ìì—° ì¦ê°€

=== í•˜ë“œì›¨ì–´ ì œì•½ ë¶„ì„ (RTX 4090) ===
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Config           â”‚ Areas     â”‚ VRAM       â”‚ í•™ìŠµ ì†ë„     â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ Vector-only í˜„ì¬ â”‚ 16        â”‚ ~3.6 GB    â”‚ 92K steps/min â”‚
  â”‚ Vector-only í™•ì¥ â”‚ 32        â”‚ ~8 GB      â”‚ ~160K/min     â”‚
  â”‚ Camera (84x84)   â”‚ 16        â”‚ ~10 GB     â”‚ ~60K/min      â”‚
  â”‚ Camera (84x84)   â”‚ 8         â”‚ ~6 GB      â”‚ ~35K/min      â”‚
  â”‚ Camera + LiDAR   â”‚ 8         â”‚ ~14 GB     â”‚ ~25K/min      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Euro NCAP LSS ì°¨ì„  ì •ì±… ê³„íš
```
=== ì°¨ì„  ë§ˆí‚¹ ìœ í˜• ë° ì •ì±… ===
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ë§ˆí‚¹ ìœ í˜•       â”‚ ì˜ë¯¸                  â”‚ Reward ì„¤ê³„  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ë°±ìƒ‰ ì ì„        â”‚ ì°¨ì„  ë³€ê²½ ê°€ëŠ¥         â”‚ í—ˆìš© (0)     â”‚
â”‚ ë°±ìƒ‰ ì‹¤ì„        â”‚ ì°¨ì„  ë³€ê²½ ê¸ˆì§€         â”‚ -2.0         â”‚
â”‚ í™©ìƒ‰ ì ì„        â”‚ ì¤‘ì•™ì„  (ì¶”ì›” ê°€ëŠ¥)     â”‚ -3.0         â”‚
â”‚ í™©ìƒ‰ ì‹¤ì„        â”‚ ì¤‘ì•™ì„  (ì¶”ì›” ê¸ˆì§€)     â”‚ -5.0         â”‚
â”‚ ì´ì¤‘ í™©ìƒ‰ ì‹¤ì„    â”‚ ì ˆëŒ€ ë„˜ì§€ ì•ŠìŒ         â”‚ -10.0 (ì¹˜ëª…) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

=== Euro NCAP ELK í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ (êµ¬í˜„ ëŒ€ìƒ) ===
1. ELK Solid Line Left/Right  - ì‹¤ì„  ì´íƒˆ ì‹œ ìë™ êµì •
2. ELK Road Edge              - ë„ë¡œ ë ì´íƒˆ ì‹œ êµì •
3. ELK Oncoming Vehicle       - ì¤‘ì•™ì„  ì¹¨ë²” ì‹œ ì—­ì£¼í–‰ ì¶©ëŒ ë°©ì§€
4. ELK Overtaking (Unintentional) - ë¹„ì˜ë„ì  ì°¨ì„  ë³€ê²½ ì¶©ëŒ ë°©ì§€
5. ELK Overtaking (Intentional)   - ì˜ë„ì  ì¶”ì›” ì‹œ ì¶©ëŒ ë°©ì§€

=== LKA í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ===
1. LKA Dashed Line  - ì ì„  ì´íƒˆ ì‹œ ê²½ê³ +êµì •
2. LKA Solid Line   - ì‹¤ì„  ì´íƒˆ ì‹œ êµì • (DTLE â‰¤ -0.3m ì´ë‚´)

=== Observation í™•ì¥ (ì°¨ì„  ì¸ì‹ìš©) ===
  lane_info: 12D (ì¶”ê°€)
    - left_lane_dist: 1D      # ì¢Œì¸¡ ì°¨ì„ ê¹Œì§€ ê±°ë¦¬
    - right_lane_dist: 1D     # ìš°ì¸¡ ì°¨ì„ ê¹Œì§€ ê±°ë¦¬
    - left_lane_type: 4D      # [ì ì„ , ë°±ì‹¤ì„ , í™©ì ì„ , í™©ì‹¤ì„ ] one-hot
    - right_lane_type: 4D     # one-hot
    - center_offset: 1D       # ì°¨ì„  ì¤‘ì•™ê¹Œì§€ offset
    - heading_error: 1D       # ì°¨ì„  ë°©í–¥ ëŒ€ë¹„ heading ì˜¤ì°¨

=== ì†ë„ êµ¬ê°„ ì •ì±… (í•œêµ­ ë„ë¡œêµí†µë²• ê¸°ë°˜) ===
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ë„ë¡œ êµ¬ê°„       â”‚ ì œí•œì†ë„              â”‚ m/s          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ì£¼ê±°/ìŠ¤ì¿¨ì¡´     â”‚ 30 km/h              â”‚ 8.3          â”‚
â”‚ ì‹œê°€ì§€ ì´ë©´ë„ë¡œ  â”‚ 50 km/h              â”‚ 13.9         â”‚
â”‚ ì¼ë°˜ë„ë¡œ (ë„ì‹œ) â”‚ 60 km/h              â”‚ 16.7         â”‚
â”‚ ìë™ì°¨ì „ìš©ë„ë¡œ   â”‚ 80 km/h              â”‚ 22.2         â”‚
â”‚ ê³ ì†ë„ë¡œ        â”‚ 100-110 km/h         â”‚ 27.8-30.6    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  ì†ë„ ìœ„ë°˜ íŒ¨ë„í‹° êµ¬ì¡°:
    10km/h ì´ˆê³¼: -0.5 (ë²”ì¹™ê¸ˆ 3ë§Œì›ê¸‰)
    20km/h ì´ˆê³¼: -1.0 (ë²”ì¹™ê¸ˆ 6ë§Œì›ê¸‰)
    40km/h ì´ˆê³¼: -2.0 (ë²”ì¹™ê¸ˆ 9ë§Œì› + ë²Œì )
    60km/h ì´ˆê³¼: -3.0 (ë©´í—ˆì •ì§€ê¸‰)

  ì ì • ì†ë„ ë³´ìƒ:
    0.8*limit â‰¤ speed â‰¤ limit: +0.3
    êµ¬ê°„ ì „í™˜ smooth ê°ì†: +0.2
    ì €ì† êµí†µë°©í•´: -0.1

=== Observation í™•ì¥ (ì†ë„ ì¸ì‹ìš©) ===
  speed_info: 4D (ì¶”ê°€)
    - current_speed_norm: 1D     # í˜„ì¬ì†ë„/max_speed
    - speed_limit_norm: 1D       # êµ¬ê°„ì œí•œì†ë„/max_speed
    - speed_ratio: 1D            # í˜„ì¬ì†ë„/ì œí•œì†ë„ (1.0 ì ì •)
    - next_speed_limit_norm: 1D  # ë‹¤ìŒ êµ¬ê°„ ì œí•œì†ë„

=== êµ¬í˜„ ìˆœì„œ (ì†ë„â†’ì°¨ì„ â†’ë„ë¡œë„¤íŠ¸ì›Œí¬â†’ì¹´ë©”ë¼) ===
Stage 4: ì†ë„ ì •ì±…
  1. ì†ë„ êµ¬ê°„ ì‹œìŠ¤í…œ (WaypointManager íƒœê·¸)
  2. Observation +4D speed_info ì¶”ê°€
  3. ì†ë„ ìœ„ë°˜ ì ì§„ì  íŒ¨ë„í‹° Reward
  4. 16 Areas í•™ìŠµ (Curriculum: ë‹¨ì¼ì†ë„ â†’ ë‹¤êµ¬ê°„)

Stage 5: ì°¨ì„  ì •ì±…
  5. ë‹¤ì°¨ì„  ë„ë¡œ í™˜ê²½ êµ¬ì¶• (2ì°¨ì„  + ì¤‘ì•™ì„ )
  6. ì°¨ì„  ë§ˆí‚¹ ì˜¤ë¸Œì íŠ¸ (Layer/Tag êµ¬ë¶„)
  7. Raycast ì°¨ì„  ê°ì§€ + Observation +12D lane_info
  8. ì°¨ì„  ìœ„ë°˜ Reward + í†µí•© í•™ìŠµ

Stage 6: ë„ë¡œ ë„¤íŠ¸ì›Œí¬ + ê²½ë¡œ ì¶”ì¢… â˜…
  9. ë„ë¡œ ê·¸ë˜í”„ ì‹œìŠ¤í…œ (IntersectionNode + RoadEdge)
  10. êµì°¨ë¡œ í”„ë¦¬íŒ¹ (Tì/ì‹­ì)
  11. Route Planner (A* ê²½ë¡œ íƒìƒ‰)
  12. Navigation Command + Observation +10D
  13. ê²½ë¡œ ì¶”ì¢… Reward (correct_turn, wrong_turn)
  14. Curriculum (ì§ì„ â†’Tìâ†’ì‹­ìâ†’ë³µí•©)

Stage 7: ì¹´ë©”ë¼ ì…ë ¥
  15. CameraSensorComponent ì¶”ê°€ (84x84 front)
  16. ML-Agents visual encoder (nature_cnn)
  17. Vector+Visual ë³µí•© í•™ìŠµ
  18. Camera-dominant í•™ìŠµ (vector ì¶•ì†Œ)

Stage 8-10: Euro NCAP + GAIL + E2E
  19. ELK/LKA ë²¤ì¹˜ë§ˆí¬
  20. Expert ì‹œì—° ë…¹í™” (ì¹´ë©”ë¼ í¬í•¨)
  21. GAIL â†’ Hybrid BCâ†’RL
  22. Full E2E (BEV + Temporal)
```

### í•™ìŠµ ì‹¤í–‰ ëª…ë ¹ì–´ ì •ë¦¬
```bash
# 1. Curriculum PPO (ì¶”ì²œ - ê°€ì¥ ë¹ ë¥¸ ìˆ˜ë ´)
mlagents-learn python/configs/planning/vehicle_ppo_curriculum.yaml --run-id=driving_ppo_curriculum_v1 --force

# 2. ê¸°ë³¸ PPO (ì´ì–´ì„œ í•™ìŠµ)
mlagents-learn python/configs/planning/vehicle_ppo.yaml --run-id=driving_ppo_v2 --force

# 3. SAC (ìƒ˜í”Œ íš¨ìœ¨ì )
mlagents-learn python/configs/planning/vehicle_sac.yaml --run-id=driving_sac_v1 --force

# 4. GAIL (ì‹œì—° ë…¹í™” í›„)
mlagents-learn python/configs/planning/vehicle_gail.yaml --run-id=driving_gail_v1 --force

# 5. Hybrid BCâ†’RL (ì‹œì—° ë…¹í™” í›„)
mlagents-learn python/configs/planning/vehicle_hybrid.yaml --run-id=driving_hybrid_v1 --force
```

### Expert ì‹œì—° ë…¹í™” ì ˆì°¨
```
1. Vehicleì— ExpertDriverController ì»´í¬ë„ŒíŠ¸ ì¶”ê°€
2. BehaviorParameters â†’ Behavior Type = "Heuristic Only"
3. DemonstrationRecorder ìë™ ì¶”ê°€ë¨ (autoRecord=true)
4. Play ëª¨ë“œ â†’ ìë™ìœ¼ë¡œ waypoint ì¶”ì¢…í•˜ë©° ì‹œì—° ë…¹í™”
5. 50 ì—í”¼ì†Œë“œ í›„ ìë™ ì •ì§€
6. ê²°ê³¼: Assets/Demonstrations/expert_driving.demo
7. ë…¹í™” í›„ BehaviorParameters â†’ "Default" (í•™ìŠµìš©)ë¡œ ë³µì›
```

### Reward Function Design (v8 - í˜„ì¬ ì ìš© ì¤‘)
```python
def compute_reward(state, action, next_state):
    # Progress reward (ëª©í‘œ ë°©í–¥ ì´ë™, ì†ë„ì œí•œ ê¸°ì¤€ ì •ê·œí™”)
    r_progress = +1.0 * progress_along_route

    # Safety reward (ì¶©ëŒ/ê·¼ì ‘ íšŒí”¼)
    r_safety = -5.0 * collision          # v8: -10â†’-5 (gradient ì•ˆì •í™”)
    r_safety += -1.5 * deltaTime * (ttc < 2.0)  # v8: rate-independent
    # off_road: -5.0 + EndEpisode (ëˆ„ì  ë°©ì§€, ì¦‰ì‹œ ì¢…ë£Œ)

    # Comfort reward (ê¸‰ê°€ì†/ê¸‰ì¡°í–¥ íŒ¨ë„í‹°)
    r_comfort = -0.1 * abs(jerk)
    r_comfort += -0.05 * abs(steering_rate)

    # Speed compliance (ì†ë„ ì •ì±…)
    r_speed = +0.3 if 0.8*speed_limit <= speed <= speed_limit
    r_speed += -0.5 ~ -3.0 * speed_over_ratio  # ì ì§„ì  ì´ˆê³¼ íŒ¨ë„í‹°

    # Goal reward
    r_goal = +10.0 * reached_destination

    return r_progress + r_safety + r_comfort + r_speed + r_goal
    # collision/off_road ì‹œ EndEpisode (ì—í”¼ì†Œë“œ ì¢…ë£Œ)
```

### v7â†’v8 Reward ë³€ê²½ êµí›ˆ
```
ë¬¸ì œ 1: collision=-10 â†’ PPO gradient explosion (Std 40+)
í•´ê²°: collision=-5ë¡œ ê°ì†Œ, ì¶©ë¶„í•œ íšŒí”¼ í•™ìŠµ ìœ ë„

ë¬¸ì œ 2: nearCollision=-0.5/frame â†’ 100í”„ë ˆì„(2ì´ˆ)ì— -150 ëˆ„ì 
í•´ê²°: Ã—Time.fixedDeltaTime ì ìš© (-1.5/ì´ˆ, rate-independent)

ë¬¸ì œ 3: offRoad=-5/sec â†’ 40ì´ˆ off-road ì‹œ -200 ëˆ„ì 
í•´ê²°: EndEpisode() ì¦‰ì‹œ ì¢…ë£Œ (1íšŒ -5 íŒ¨ë„í‹°)

ë¬¸ì œ 4: NPC 0â†’2 + goal 50â†’120m ë™ì‹œ ì§„í–‰
í•´ê²°: NPC/goal ì„ê³„ê°’ ë¶„ë¦¬, NPC 0â†’1â†’2â†’4 ì ì§„ì  ë„ì…
```

### RL Training Configuration
```yaml
# PPO Config
algorithm: PPO
policy:
  hidden_layers: [512, 512, 256]
  activation: tanh
hyperparameters:
  batch_size: 2048
  buffer_size: 20480
  learning_rate: 3e-4
  num_epoch: 3
  epsilon: 0.2  # clip ratio
  gamma: 0.99
  lambda: 0.95
  beta: 0.005  # entropy bonus
max_steps: 10_000_000
curriculum:
  - lesson_0: straight road only
  - lesson_1: + gentle curves
  - lesson_2: + intersections
  - lesson_3: + traffic vehicles
  - lesson_4: + pedestrians + complex scenarios
```

### Unity Environment Requirements
```csharp
// DrivingAgent observation space for E2E
ObservationSpec:
  - CameraImages: 8 x [3, 84, 84] (downscaled for RL)
    OR
  - VectorObservation: 238D (ego+agents+route)

ActionSpec:
  - ContinuousActions: 2 (steering, acceleration)

Rewards:
  - Per-step reward (composite)
  - Episode termination on collision/goal
```

### Success Criteria (RL Phase)
| Metric | Target |
|--------|--------|
| Collision Rate | < 5% |
| Route Completion | > 85% |
| Comfort (jerk < 2m/s^3) | > 80% episodes |
| Average Reward | > 500/episode |

---

## Phase 6: Hybrid Training & Deployment

### Objectives
IL + RL ê²°í•© (CIMRL) ë° Unity/ROS2 ì‹¤ì‹œê°„ ë°°í¬

### Task Breakdown

| ID | Task | Priority | Status |
|----|------|----------|--------|
| P6-01 | CIMRL êµ¬í˜„ (IL ì´ˆê¸°í™” â†’ RL fine-tuning) | High | â³ |
| P6-02 | ONNX Export íŒŒì´í”„ë¼ì¸ | High | â³ |
| P6-03 | Unity Sentis ì¶”ë¡  í†µí•© | High | â³ |
| P6-04 | ROS2 Control Publisher | Medium | â³ |
| P6-05 | ì‹¤ì‹œê°„ ì„±ëŠ¥ ìµœì í™” (<50ms) | High | â³ |
| P6-06 | ë²¤ì¹˜ë§ˆí¬ í‰ê°€ (nuPlan scoring) | High | â³ |
| P6-07 | Ablation Study | Medium | â³ |
| P6-08 | ìµœì¢… ëª¨ë¸ ì„ ì • ë° ë¬¸ì„œí™” | Medium | â³ |

### Hybrid Training Strategy (CIMRL)
```
Step 1: Pre-train with IL (nuPlan expert data)
  â†’ model_il.pt (good initialization, safe driving)

Step 2: Fine-tune with RL (Unity sim)
  â†’ model_rl.pt (optimized for reward, exceeds expert)

Step 3: Evaluate & Select
  â†’ Compare IL-only, RL-only, Hybrid
  â†’ Select best model by composite score

Step 4: Export & Deploy
  â†’ torch.onnx.export(best_model) â†’ model.onnx
  â†’ Unity Sentisë¡œ ë¡œë“œ â†’ ì‹¤ì‹œê°„ ì¶”ë¡ 
  â†’ ROS2 /vehicle/control í† í”½ìœ¼ë¡œ publish
```

### Deployment Pipeline
```
PyTorch (.pt)
  â†’ torch.onnx.export()
  â†’ model.onnx (ONNX format)
  â†’ Unity Sentis ModelLoader.Load()
  â†’ Worker.Schedule(input_tensor)
  â†’ output: [steering, acceleration]
  â†’ vehicle.ApplyControl()
  â†’ ROS2 publish (optional)
```

### Final Success Criteria

| Category | Metric | Target | Weight |
|----------|--------|--------|--------|
| Safety | Collision Rate | < 5% | 30% |
| Comfort | Jerk | < 2 m/s^3 | 20% |
| Progress | Route Completion | > 85% | 25% |
| Latency | Inference time | < 50ms | 15% |
| Generalization | Unseen scenarios | > 70% success | 10% |

---

## Phase 7: Advanced Topics

### Research Areas
- World Model for Driving (GAIA-1 style)
- Vision-Language-Action (VLA) Integration
- Sim-to-Real Transfer Techniques
- Multi-agent Cooperative Driving
- Adversarial Robustness Testing

---

## Recent Activity Log

| Date | Activity | Status |
|------|----------|--------|
| 2026-01-24 | **Stage 4 v8 í•™ìŠµ ì§„í–‰ ì¤‘** (3.07M/8M, NPC+ì†ë„ì •ì±…, Best +2.46) | ğŸ”„ |
| 2026-01-24 | **Reward ì¬ì¡°ì •** (collision=-5, nearCollision rate-independent, off-road termination) | âœ… |
| 2026-01-24 | **Curriculum ì¬ì„¤ê³„** (NPC 0â†’1â†’2â†’4 ì ì§„ì , threshold ë¶„ë¦¬) | âœ… |
| 2026-01-24 | **32 Areas í™•ì¥ ê³„íš** (Stage 4 ì™„ë£Œ í›„ ì ìš©) | â³ |
| 2026-01-24 | **ì¹´ë©”ë¼/LiDAR ë³‘ë ¬ ì œí•œ ê²€í† ** (8-16 Areas) | âœ… |
| 2026-01-24 | **ì‹ í˜¸ë“± ì¸ì‹ í•™ìŠµ ê³„íš í™•ì¸** (Phase 6 ë²”ìœ„) | âœ… |
| 2026-01-23 | **Tesla-style E2E ì•„í‚¤í…ì²˜ ê²°ì •** | âœ… |
| 2026-01-23 | **ê°œë°œ ê³„íš ì „ë©´ ì—…ë°ì´íŠ¸ (E2E ë°˜ì˜)** | âœ… |
| 2026-01-23 | **Tesla FSD ê¸°ìˆ  ì¡°ì‚¬** (docs/knowledge/tesla-fsd-technology.md) | âœ… |
| 2026-01-23 | **AD ê¸°ì—…/ì—°êµ¬ì†Œ ì¡°ì‚¬** (docs/knowledge/AD-research-landscape.md) | âœ… |
| 2026-01-23 | **Phase 2 êµ¬í˜„**: nuPlan loader, processor, augmentation, visualizer, splitter | âœ… |
| 2026-01-23 | **Phase 1 ì™„ë£Œ** | âœ… |
| 2026-01-23 | **ì‹¤í—˜ ì¶”ì  ì„¤ì •** (MLflow/W&B) | âœ… |
| 2026-01-23 | **LiDARSensor êµ¬í˜„** (16x360 ë ˆì´ìºìŠ¤íŒ…) | âœ… |
| 2026-01-23 | **CameraSensor êµ¬í˜„** (640x480 RGB, ROS Publish) | âœ… |
| 2026-01-23 | **VehicleROSBridge êµ¬í˜„** (Pub/Sub) | âœ… |
| 2026-01-23 | **í‚¤ë³´ë“œ ì£¼í–‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ** | âœ… |
| 2026-01-23 | **VehicleAgent + SimpleVehicleController ìƒì„±** | âœ… |
| 2026-01-22 | **ROS2 â†” Unity ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ** | âœ… |
| 2026-01-22 | **ê¸°ë³¸ ì£¼í–‰ Scene (DrivingScene) ìƒì„±** | âœ… |
| 2026-01-22 | **Unity ROS-TCP-Connector ì„¤ì¹˜** | âœ… |
| 2026-01-22 | **WSL2 + ROS2 Humble + ROS-TCP-Endpoint ì„¤ì¹˜** | âœ… |
| 2026-01-22 | **Phase 1-7 Obsidian ì§€ì‹í™” ì„¹ì…˜ ì¶”ê°€** | âœ… |
| 2026-01-22 | **ML-Agents 4.0.1 + Unity 6 í™˜ê²½ êµ¬ì¶•** | âœ… |
| 2026-01-22 | **Sentis 2.4.1 ì„¤ì¹˜ (Barracuda ëŒ€ì²´)** | âœ… |
| 2026-01-22 | **3DBall PPO í•™ìŠµ ì„±ê³µ (5ë¶„, Reward 100)** | âœ… |
| 2026-01-22 | **ONNX ëª¨ë¸ Export ì™„ë£Œ** | âœ… |
| 2026-01-22 | **ë¬¸ì„œ ì—…ë°ì´íŠ¸ (TECH-SPEC, PRD, CLAUDE.md)** | âœ… |
| 2026-01-22 | AD í”Œë«í¼ìœ¼ë¡œ í”„ë¡œì íŠ¸ ì¬êµ¬ì„± | âœ… |
| 2026-01-22 | 7-Phase ì‹œìŠ¤í…œ ì„¤ê³„ | âœ… |
| 2026-01-22 | PRD, TECH-SPEC ë¬¸ì„œ ì‘ì„± | âœ… |
| 2026-01-21 | í”„ë¡œì íŠ¸ ì´ˆê¸°í™”, êµ¬ì¡° ì„¤ê³„ | âœ… |
| 2026-01-21 | cc-initializer ì—°ë™ | âœ… |

---

## Notes & Decisions

### Current Environment (2026-01-27)
| Component | Version | Notes |
|-----------|---------|-------|
| OS | Windows 11 | Native (WSL ë¯¸ì‚¬ìš©) |
| Unity | 6000.3.4f1 (Unity 6) | LTS |
| ML-Agents | 4.0.1 | Unity Package |
| Sentis | 2.4.1 | ONNX Inference |
| Python | 3.10.11 | Windows Native |
| PyTorch | 2.3.1 | CUDA 12.x |
| mlagents | 1.2.0 | Python Package |

> **Note**: ì´ˆê¸°ì— ROS2 (WSL2)ë¥¼ ì„¤ì •í–ˆìœ¼ë‚˜, ML-Agents ì§ì ‘ í†µì‹ ì´ ë” íš¨ìœ¨ì ì´ì–´ì„œ í˜„ì¬ëŠ” ML-Agents ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ ì§„í–‰ ì¤‘

### Key Decisions
1. **ROS2 Bridge**: âœ… Unity Robotics Hub (ROS-TCP-Connector) ì„ íƒ *(ì´ˆê¸° ì„¤ì •, í˜„ì¬ ë¯¸ì‚¬ìš©)*
2. **ROS2 í™˜ê²½**: âœ… WSL2 Ubuntu 22.04 + ROS2 Humble *(ì´ˆê¸° ì„¤ì •, í˜„ì¬ ML-Agents ì‚¬ìš©)*
3. **Architecture**: âœ… **Tesla-style E2E** (modular ëŒ€ì‹  unified neural net)
4. **Sensor**: âœ… **Camera-only** (Vision-only, no LiDAR for planning)
5. **Learning**: IL (nuPlan) â†’ RL (Unity) â†’ Hybrid (CIMRL)
6. **Inference**: PyTorch â†’ ONNX â†’ Unity Sentis
7. **Action Space**: steering [-0.5, +0.5] rad, acceleration [-4.0, +2.0] m/s^2
8. **No separate Control layer**: Planning Networkì´ ì§ì ‘ ì œì–´ ì¶œë ¥

### Architecture Decision Record (ADR)
```
ADR-001: Tesla-style E2E vs Modular Pipeline
  Decision: E2E (End-to-End)
  Date: 2026-01-23
  Reason:
    - Unified gradient flow (joint optimization)
    - Error cascade ì œê±°
    - ì½”ë“œ ë³µì¡ë„ ê°ì†Œ
    - Tesla FSD v12+ ê²€ì¦ëœ ì ‘ê·¼ë²•
  Trade-off:
    - ë””ë²„ê¹… ì–´ë ¤ì›€ (intermediate output ì—†ìœ¼ë©´)
    - í•´ê²°: Auxiliary losses (occupancy, lane prediction)

ADR-002: Simplified Start (Level 1 â†’ Level 4)
  Decision: MLP Plannerë¶€í„° ì‹œì‘, ì ì§„ì  í™•ì¥
  Reason:
    - ì „ì²´ ëª¨ë¸ í•œë²ˆì— êµ¬í˜„ ì‹œ ë””ë²„ê¹… ë¶ˆê°€ëŠ¥
    - ê° Levelì—ì„œ íŒŒì´í”„ë¼ì¸ ê²€ì¦
    - Level 1 (MLP) â†’ Level 2 (+ ResNet) â†’ Level 3 (+ BEV) â†’ Level 4 (Full E2E)

ADR-003: Modular Encoder Architecture for Incremental Learning
  Decision: Implement modular encoder with freeze/unfreeze capability
  Date: 2026-01-25
  Problem:
    - Observation space changes (242D â†’ 254D for lane info) cause full training restart
    - ML-Agents initialize_from requires matching dimensions
    - Phase B training (+903 reward) was lost when adding lane observation
  Solution:
    - Named encoder modules (ego, history, agents, route, speed, lane)
    - Freeze/unfreeze capability per module
    - Dynamic encoder addition with fusion weight transfer
    - Two-phase training: new encoder (500K) â†’ fine-tune all (1.5M)
  Research References:
    - Progressive Neural Networks (freeze columns approach)
    - UPGD (ICLR 2024) - Utility-based Perturbed Gradient Descent
    - EWC (Elastic Weight Consolidation)
  Expected Benefit:
    - Phase B knowledge preserved (~+700 reward at start of C-1)
    - Future observation additions: add encoder + partial train (vs full restart)
  Implementation:
    - python/src/models/modular_encoder.py
    - python/src/models/modular_policy.py
    - python/src/training/train_modular_rl.py
    - python/configs/planning/modular_ppo_phaseC1.yaml
```

### Next Actions
1. **Phase 3 ì‹œì‘**: E2E ëª¨ë¸ ì•„í‚¤í…ì²˜ êµ¬í˜„
2. Level 1 (MLP Planner) ë¨¼ì € êµ¬í˜„ â†’ IL íŒŒì´í”„ë¼ì¸ ê²€ì¦
3. Level 2-4 ì ì§„ì  í™•ì¥

---
layout: default
title: Home
---

# Autonomous Driving ML Platform

Unity ML-Agents ê¸°ë°˜ ììœ¨ì£¼í–‰ Motion Planning AI í•™ìŠµ í”„ë¡œì íŠ¸

---

## Project Overview

ê°•í™”í•™ìŠµ(RL)ì„ í™œìš©í•˜ì—¬ ììœ¨ì£¼í–‰ ì°¨ëŸ‰ì˜ ì˜ì‚¬ê²°ì • ëŠ¥ë ¥ì„ í•™ìŠµì‹œí‚¤ëŠ” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

### Tech Stack

| Component | Technology |
|-----------|------------|
| Simulation | Unity 6 (6000.x) |
| ML Framework | ML-Agents 4.0, PyTorch 2.3 |
| Inference | Unity Sentis 2.4 |
| Algorithm | PPO (Proximal Policy Optimization) |

### Training Environment

- **16 Parallel Training Areas**: ë™ì‹œ í•™ìŠµìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘ ê°€ì†í™”
- **Curriculum Learning**: ë‹¨ê³„ë³„ ë‚œì´ë„ ì¦ê°€ë¡œ ì ì§„ì  í•™ìŠµ
- **254D Observation Space**: ìì°¨ ìƒíƒœ, ì£¼ë³€ ì°¨ëŸ‰, ê²½ë¡œ ì •ë³´ ë“±

---

## Training Progress

### Completed Phases

| Phase | Focus | Best Reward | Key Achievement |
|-------|-------|-------------|-----------------|
| [Phase A](./phases/phase-a) | ê¸°ë³¸ ì¶”ì›” | **+937** | Dense rewardë¡œ ì¶”ì›” ê¸°ë™ í•™ìŠµ |
| [Phase B](./phases/phase-b) | ì¶”ì›” íŒë‹¨ | **+994** | ì¶”ì›” vs ë”°ë¼ê°€ê¸° ì˜ì‚¬ê²°ì • |
| [Phase C](./phases/phase-c) | ë‹¤ì¤‘ NPC | **+1086** | 4ëŒ€ NPC í™˜ê²½ ì¼ë°˜í™” |
| [Phase E](./phases/phase-e) | ê³¡ì„  ë„ë¡œ | **+931** | ê³¡ë¥  1.0ê¹Œì§€ ì£¼í–‰ |
| [Phase F](./phases/phase-f) | ë‹¤ì¤‘ ì°¨ì„  | **+988** | 2ì°¨ì„  + ì¤‘ì•™ì„  ê·œì¹™ |

### Current Training

**Phase G: Intersection Navigation** ğŸ”„

êµì°¨ë¡œ (Tì/ì‹­ì/Yì) ì£¼í–‰ í•™ìŠµ ì¤‘

```
Progress: â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 10%
Reward:   +492 â†’ target: +800
```

[Phase G ìƒì„¸ ë³´ê¸°](./phases/phase-g)

---

## Reward Evolution

```
v10g:    â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  +40  (ì¶”ì›” ë¶ˆê°€)
v11:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  +51  (Sparse ì‹¤íŒ¨)
Phase A: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘  +937 (ì¶”ì›” ì„±ê³µ!)
Phase B: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘  +994 (íŒë‹¨ë ¥)
Phase C: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘  +1086 (ì¼ë°˜í™”)
Phase E: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘  +931 (ê³¡ì„  ë„ë¡œ)
Phase F: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘  +988 (ë‹¤ì¤‘ ì°¨ì„ )
Phase G: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  +492 (êµì°¨ë¡œ í•™ìŠµì¤‘)
```

---

## Gallery

### Training Screenshots

| Phase E: Curved Road | Phase F: Multi-Lane | Phase G: Intersection |
|---------------------|---------------------|----------------------|
| ![Curved](./gallery/screenshots/phase-e-curved.png) | ![Multi-lane](./gallery/screenshots/phase-f-multilane.png) | ![Intersection](./gallery/screenshots/phase-g-intersection.png) |

### Demo Videos

- [Phase A: ì²« ì¶”ì›” ì„±ê³µ](./gallery/videos/phase-a-overtake.mp4)
- [Phase F: ë‹¤ì°¨ì„  ì£¼í–‰](./gallery/videos/phase-f-demo.mp4)

---

## Key Insights

### What Worked âœ…

1. **Dense Reward > Sparse Reward**: ì¶”ì›” ê³¼ì • ì „ì²´ì— ë³´ìƒ í•„ìš”
2. **Curriculum Learning**: ì ì§„ì  ë‚œì´ë„ ì¦ê°€ê°€ í•µì‹¬
3. **targetSpeed = speedLimit**: ì ˆëŒ€ NPC ì†ë„ë¡œ ë‚®ì¶”ë©´ ì•ˆ ë¨

### What Failed âŒ

1. **followingBonus**: ë”°ë¼ê°€ê¸°ë¥¼ ë³´ìƒí•˜ë©´ ì¶”ì›” í•™ìŠµ ë¶ˆê°€
2. **Encoder Fine-tuning**: Catastrophic forgetting ë°œìƒ
3. **ê¸‰ê²©í•œ í™˜ê²½ ë³€í™”**: ì»¤ë¦¬í˜ëŸ¼ ì¶©ê²©ìœ¼ë¡œ í•™ìŠµ ë¶•ê´´

[ì „ì²´ êµí›ˆ ë³´ê¸°](./lessons-learned)

---

## Resources

- [GitHub Repository](https://github.com/[username]/physical-unity)
- [Training Log (Detailed)](./training-log)
- [Learning Roadmap](./roadmap)

---

*Last Updated: 2026-01-27*

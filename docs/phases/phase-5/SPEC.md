# Phase 5: Planning Models (PRIMARY FOCUS)

> **í•™ìŠµ ë¡œë“œë§µ**: ìƒì„¸ í•™ìŠµ ê³„íšì€ [LEARNING-ROADMAP.md](../../LEARNING-ROADMAP.md) ì°¸ì¡°
>
> ì´ ë¬¸ì„œëŠ” Phase 5ì˜ **ê¸°ìˆ  ì„¤ê³„** ë° **ì•„í‚¤í…ì²˜**ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.
> ì‹¤ì œ í•™ìŠµ ì§„í–‰ (Phase A-L)ì€ LEARNING-ROADMAP.mdì—ì„œ ê´€ë¦¬ë©ë‹ˆë‹¤.

## Overview

**í”„ë¡œì íŠ¸ì˜ í•µì‹¬ Phase**. ê°•í™”í•™ìŠµ(RL)ê³¼ ëª¨ë°©í•™ìŠµ(IL) ê¸°ë°˜ ëª¨ì…˜ í”Œë˜ë‹ ëª¨ë¸ì„ ê°œë°œí•©ë‹ˆë‹¤.

## Goals

1. **RL ì‹¤í—˜**: PPO, SAC ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ëª¨ì…˜ í”Œë˜ë‹
2. **IL ì‹¤í—˜**: Behavioral Cloning, GAILë¡œ Expert ëª¨ë°©
3. **Hybrid ëª¨ë¸**: IL ì´ˆê¸°í™” + RL Fine-tuning (CIMRL)
4. **Ablation Study**: ê° ìš”ì†Œë³„ ê¸°ì—¬ë„ ë¶„ì„

## Strategy

```
ì‹¤í—˜ ìˆœì„œ (Revised - 2026-01-24):

Phase 5A: Vector-based RL (ë²¡í„° ê´€ì¸¡ ê¸°ë°˜ ì •ì±… í•™ìŠµ)
  1. âœ… Behavioral Cloning (BC) â†’ Baseline í™•ë¦½
  2. âœ… Pure RL (PPO Single Area) â†’ 950K steps, Reward ~700
  3. âœ… ë³‘ë ¬ Training Areas (16x) â†’ 1.66M steps, Reward ~750 ìˆ˜ë ´
  4. ğŸ”„ ì†ë„ ì •ì±… (v8) â†’ 3.07M/8M, NPC+ì†ë„, Best +2.46
     - Reward ì¬ì¡°ì •: collision=-5, nearCollision rate-independent, off-road termination
     - Curriculum ì¬ì„¤ê³„: NPC 0â†’1â†’2â†’4 (ì ì§„ì ), threshold ë¶„ë¦¬
     - â˜… ì™„ë£Œ í›„: 32 Areas í™•ì¥ ì ìš©
  5. â³ Multi-Lane + ì°¨ì„  ì •ì±… â†’ 32 Areas, 5ì¢… ë§ˆí‚¹
  6. â³ ë„ë¡œ ë„¤íŠ¸ì›Œí¬ + êµì°¨ë¡œ + ê²½ë¡œ ì¶”ì¢… â† â˜… í•µì‹¬

Phase 5B: Vision-based RL (ì¹´ë©”ë¼ ì…ë ¥ í•™ìŠµ, 8-16 Areas)
  7. â³ Camera ì…ë ¥ (Level 2) â†’ nature_cnn/resnet encoder, 8-16 Areas
  8. â³ Euro NCAP + ì‹ í˜¸ë“± ì¸ì‹ â†’ ELK/LKA + ì¹´ë©”ë¼ ì‹ í˜¸ì²´ê³„

Phase 5C: Hybrid & Advanced (ëª¨ë°©í•™ìŠµ ê²°í•©)
  9. â³ Expert ë…¹í™” â†’ GAIL/Hybrid (ì¹´ë©”ë¼ ê¸°ë°˜ ì‹œì—°)
  10. â³ Full E2E (Level 3-4) â†’ BEV + Temporal + Planning
  11. â³ Ablation Studies â†’ ë¶„ì„

ì›ì¹™: "ë²¡í„° ê¸°ë°˜ì—ì„œ ì •ì±… ê²€ì¦ â†’ ì¹´ë©”ë¼ ì¶”ê°€ â†’ E2E í†µí•©"
       (ë””ë²„ê¹…: ë¹„ì „ ë¬¸ì œ vs ì •ì±… ë¬¸ì œ ë¶„ë¦¬ ê°€ëŠ¥í•´ì•¼ í•¨)

ë³‘ë ¬í™” ì „ëµ:
  - Vector-only (Stage 4-6): 32 Areas (RTX 4090 VRAM ~8GB)
  - Camera (Stage 7-8): 8-16 Areas (ë Œë”ë§ ë¶€í•˜ë¡œ ì¶•ì†Œ)
  - Sensor í†µí•© (Phase 6): 8 Areas (Camera + LiDAR)
```

## Scope

### In Scope
- PPO ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ ë° í•™ìŠµ
- SAC ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ ë° í•™ìŠµ
- Behavioral Cloning êµ¬í˜„ ë° í•™ìŠµ
- GAIL êµ¬í˜„ ë° í•™ìŠµ
- Hybrid RL+IL (CIMRL) êµ¬í˜„
- ë³´ìƒ í•¨ìˆ˜ ì„¤ê³„ ë° íŠœë‹
- Observation/Action space ì„¤ê³„
- ì„±ëŠ¥ í‰ê°€ ë° ë¹„êµ
- **ë³‘ë ¬ Training Areas (16x)** - GPU í™œìš© ê·¹ëŒ€í™”
- **ë‹¤ì°¨ì„  ë„ë¡œ í™˜ê²½** - 2ì°¨ì„  + ì¤‘ì•™ì„  + ê°“ê¸¸
- **ì°¨ì„  ë§ˆí‚¹ ì •ì±…** - 5ì¢… ì°¨ì„  (ì‹¤ì„ /ì ì„ /í™©ìƒ‰/ì´ì¤‘)
- **ì†ë„ ì œí•œ ì •ì±…** - êµ¬ê°„ë³„ ì œí•œì†ë„ (30/50/60/80 km/h), í•œêµ­ ë„ë¡œêµí†µë²• ê¸°ë°˜
- **ë„ë¡œ ë„¤íŠ¸ì›Œí¬ + êµì°¨ë¡œ** - Tì/ì‹­ì êµì°¨ë¡œ, ê²½ë¡œ ê·¸ë˜í”„ íƒìƒ‰
- **ê²½ë¡œ ì¶”ì¢… (Navigation)** - ëª©ì ì§€ ì„¤ì • â†’ ê²½ë¡œ ìƒì„± â†’ êµì°¨ë¡œ ê²°ì •
- **Camera Visual Observation** - ML-Agents CameraSensor + CNN encoder
- **Euro NCAP LSS í‰ê°€** - ELK/LKA ì‹œë‚˜ë¦¬ì˜¤ ë²¤ì¹˜ë§ˆí¬

### Out of Scope
- ì‹¤ì°¨ ì ìš© (Sim-to-Real)
- Model-based RL
- World Model

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Phase 5: Planning Models (PRIMARY FOCUS)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                         EXPERIMENT PIPELINE                             â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚   â”‚                    STAGE 1: Behavioral Cloning                   â”‚  â”‚ â”‚
â”‚  â”‚   â”‚  nuPlan Expert Data â†’ Supervised Learning â†’ BC Baseline          â”‚  â”‚ â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                                     â”‚                                   â”‚ â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚   â”‚                    STAGE 2: Pure RL (PPO/SAC)                    â”‚  â”‚ â”‚
â”‚  â”‚   â”‚  Random Init â†’ Reward Shaping â†’ Policy Optimization              â”‚  â”‚ â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                                     â”‚                                   â”‚ â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚   â”‚                    STAGE 3: GAIL                                 â”‚  â”‚ â”‚
â”‚  â”‚   â”‚  Expert Data â†’ Discriminator â†’ Policy w/o Reward                 â”‚  â”‚ â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                                     â”‚                                   â”‚ â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚   â”‚                    STAGE 4: Hybrid (CIMRL)                       â”‚  â”‚ â”‚
â”‚  â”‚   â”‚  BC Initialization â†’ RL Fine-tuning â†’ Final Model                â”‚  â”‚ â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                                     â”‚                                   â”‚ â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚   â”‚                    STAGE 5: Ablation Studies                     â”‚  â”‚ â”‚
â”‚  â”‚   â”‚  Reward Components, Network Architecture, Hyperparameters        â”‚  â”‚ â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                         MODEL ARCHITECTURE                              â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚                    Observation Encoder                           â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Ego State â”‚  â”‚Route Info â”‚  â”‚Surroundingâ”‚  â†’ Fusion â†’ 256D   â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  â”‚    8D     â”‚  â”‚   30D     â”‚  â”‚   40D     â”‚                    â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â”‚                                    â”‚                                    â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚                    Policy Network (Actor)                        â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  256D â†’ 256 â†’ 256 â†’ [Î¼_acc, Î¼_steer] / [Ïƒ_acc, Ïƒ_steer]         â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â”‚                                    â”‚                                    â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚                    Value Network (Critic)                        â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  256D â†’ 256 â†’ 256 â†’ V(s)                                         â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Observation Space Design

```yaml
# ë‹¨ê³„ë³„ Observation í™•ì¥:
#   Stage 1-3: 140D (ê¸°ë³¸)
#   Stage 4:   160D (+lane 12D, +speed 4D, +navigation 10D ë¯¸í¬í•¨)
#   Stage 6:   170D (+navigation 10D)
#   Stage 7:   170D + visual observations (Camera CNN)

# === Base Observation (Stage 1-3): 140D ===
ego_state: 8D
  - position: [x, y]           # 2D
  - velocity: [vx, vy]         # 2D
  - heading: [sin, cos]        # 2D
  - acceleration: [ax, ay]     # 2D

route_info: 30D
  - waypoints: 10 x [x, y]     # 20D (ê²½ë¡œë¥¼ ë”°ë¥¸ ê³¡ì„  í¬í•¨)
  - distances: 10              # 10D

surrounding: 40D
  - vehicles: 8 x [x, y, vx, vy, heading]  # 40D

bev_features: 64D (optional, Stage 7+)
  - encoded BEV representation

# === Stage 4 í™•ì¥: +16D (lane + speed) ===
lane_info: 12D
  - left_lane_dist: 1D
  - right_lane_dist: 1D
  - left_lane_type: 4D (one-hot)
  - right_lane_type: 4D (one-hot)
  - center_offset: 1D
  - heading_error: 1D

speed_info: 4D
  - current_speed_norm: 1D
  - speed_limit_norm: 1D
  - speed_ratio: 1D
  - next_speed_limit_norm: 1D

# === Stage 6 í™•ì¥: +10D (navigation) ===
navigation_command: 6D
  - one-hot: [ì§ì§„, ì¢ŒíšŒì „, ìš°íšŒì „, ìœ í„´, ì¢Œì°¨ì„ ë³€ê²½, ìš°ì°¨ì„ ë³€ê²½]
  - êµì°¨ë¡œ ì ‘ê·¼ ì‹œ ë‹¤ìŒ í–‰ë™ ì§€ì‹œ

intersection_info: 4D
  - distance_to_intersection: 1D   # ë‹¤ìŒ êµì°¨ë¡œê¹Œì§€ ê±°ë¦¬ (ì •ê·œí™”)
  - intersection_type: 1D          # Tì=0.33, ì‹­ì=0.67, ë¡œí„°ë¦¬=1.0
  - entry_angle: 1D                # ì§„ì… ê°ë„ (ì •ê·œí™”, -1~1)
  - exit_angle: 1D                 # ì¶œêµ¬ ê°ë„ (ì •ê·œí™”, -1~1)

# === Stage 7 í™•ì¥: Visual Observation ===
camera_observation:
  - resolution: [84, 84, 3]        # ML-Agents CameraSensor
  - vis_encode_type: nature_cnn    # or resnet
  - cameras: 1 (front-facing)      # í™•ì¥: 3 (front + left + right)
  - ë³„ë„ CNN encoder â†’ 128D embedding â†’ Policy inputì— concat
```

## Action Space Design

```yaml
# Continuous Action Space
continuous:
  acceleration:
    range: [-4.0, 2.0]    # m/sÂ² (braking to acceleration)
    description: "Longitudinal control"

  steering:
    range: [-0.5, 0.5]    # rad (left to right)
    description: "Lateral control"

# Alternative: Discrete (for initial experiments)
discrete:
  acceleration: [-4, -2, 0, 1, 2]  # 5 levels
  steering: [-0.3, -0.15, 0, 0.15, 0.3]  # 5 levels
```

## Reward Function Design

```yaml
# Composite Reward Function (v8 - í˜„ì¬ ì ìš© ì¤‘)
#
# í•µì‹¬ ì›ì¹™ (v7â†’v8 êµí›ˆ):
#   1. íŒ¨ë„í‹°ëŠ” episode terminationìœ¼ë¡œ ì²˜ë¦¬ (ëˆ„ì  ë°©ì§€)
#   2. ì—°ì† íŒ¨ë„í‹°ëŠ” rate-independent (Ã—deltaTime)
#   3. ì¶©ëŒ íŒ¨ë„í‹°ëŠ” gradient stability ê³ ë ¤í•˜ì—¬ ì ì • ìˆ˜ì¤€ ìœ ì§€
#   4. Curriculumì€ í•œ ë²ˆì— í•˜ë‚˜ì˜ ì°¨ì›ë§Œ ì–´ë µê²Œ ë³€ê²½

# === Base Rewards ===
progress: +1.0
  description: "Progress towards goal (normalized, capped at speed_limit)"
  formula: "dot(velocity, goal_direction) / min(max_speed, speed_limit)"
  note: "Stage 4ì—ì„œ max_speed ëŒ€ì‹  speed_limitìœ¼ë¡œ ì •ê·œí™” (ì´ˆê³¼ ì†ë„ì— ë³´ìƒ ì œê±°)"

goal_reached: +10.0
  description: "Bonus for reaching goal"
  condition: "distance_to_goal < 2.0m"

# === Safety Penalties (v8 ì¡°ì •) ===
collision: -5.0                    # v8: -10â†’-5 (PPO gradient ì•ˆì •í™”)
  description: "Collision with any object"
  terminates: true                 # EndEpisode() ì¦‰ì‹œ ì¢…ë£Œ

near_collision: -1.5 * deltaTime   # v8: rate-independent (ì´ˆë‹¹ -1.5)
  description: "Time-to-Collision < threshold"
  formula: "-1.5 * Time.fixedDeltaTime if TTC < 2.0"
  note: "í”„ë ˆì„ìœ¨ì— ë¬´ê´€í•œ ì¼ì • íŒ¨ë„í‹°/ì´ˆ"

off_road: -5.0                     # v8: ëˆ„ì  â†’ ì¦‰ì‹œ ì¢…ë£Œ
  description: "Vehicle leaves drivable area"
  terminates: true                 # EndEpisode() ì¦‰ì‹œ ì¢…ë£Œ (ëˆ„ì  ë°©ì§€)
  note: "v7ì—ì„œ -5/sec ëˆ„ì  â†’ -200ê¹Œì§€ ë„ë‹¬í•˜ì—¬ policy collapse ë°œìƒ"

# === Comfort Rewards ===
jerk: -0.1
  description: "Penalize sudden acceleration changes"
  formula: "-0.1 * |d(acceleration)/dt|"

lateral_acc: -0.05
  description: "Penalize high lateral acceleration"
  formula: "-0.05 * |lateral_acceleration|"

steering_rate: -0.02
  description: "Penalize rapid steering"
  formula: "-0.02 * |steering - prev_steering| / dt"

# === Traffic Rules ===
lane_keeping: +0.5
  description: "Bonus for staying in lane"
  condition: "center_offset < 0.5m"

speed_compliance: +0.3
  description: "Reward for maintaining optimal speed (80-100% of limit)"
  formula: "+0.3 if 0.8*speed_limit <= speed <= speed_limit"

speed_over_limit: -0.5 ~ -3.0
  description: "Progressive penalty for exceeding speed limit"
  formula: |
    over_ratio = (speed - speed_limit) / speed_limit
    if over_ratio > 0:    penalty = -0.5 * min(over_ratio * 10, 6.0)
    # 10% ì´ˆê³¼: -0.5, 20% ì´ˆê³¼: -1.0, 50%+ì´ˆê³¼: -3.0

speed_under_limit: -0.1
  description: "Mild penalty for driving too slowly (obstructing traffic)"
  condition: "speed < 0.5 * speed_limit AND no obstacle ahead"

traffic_light: -5.0
  description: "Penalty for running red light (Phase 6 êµ¬í˜„ ì˜ˆì •)"
```

### Reward ì„¤ê³„ êµí›ˆ (v7â†’v8)

```yaml
# === Policy Collapse ì›ì¸ ë¶„ì„ ===
#
# ë¬¸ì œ 1: collision=-10 â†’ Std of Reward 40+ â†’ PPO gradient explosion
#   í•´ê²°: -5ë¡œ ì™„í™”. ì¶©ëŒ ì‹œ EndEpisodeë¡œ ì¶©ë¶„í•œ í•™ìŠµ ì‹ í˜¸ ì „ë‹¬.
#   ê·¼ê±°: PPO clip ratio(Îµ=0.2)ë¡œëŠ” reward ë²”ìœ„ê°€ ë„“ì„ ë•Œ ë¶ˆì•ˆì •.
#
# ë¬¸ì œ 2: nearCollision=-0.5/frame (50fpsì—ì„œ 2ì´ˆê°„ -50 ëˆ„ì )
#   í•´ê²°: Ã—Time.fixedDeltaTime â†’ -1.5/ì´ˆ (frame rate ë¬´ê´€)
#   ê³µì‹: reward += nearCollisionPenalty * Time.fixedDeltaTime
#
# ë¬¸ì œ 3: offRoad=-5/sec (40ì´ˆ off-road â†’ -200 ëˆ„ì )
#   í•´ê²°: EndEpisode() ì¦‰ì‹œ ì¢…ë£Œ. ììœ¨ì£¼í–‰ RL í‘œì¤€ ì ‘ê·¼ë²•.
#   ì°¸ê³ : ì¶©ëŒê³¼ ë™ì¼í•˜ê²Œ ì¹˜ëª…ì  ì‹¤íŒ¨ë¡œ ë¶„ë¥˜.
#
# ë¬¸ì œ 4: NPC 0â†’2 + goal 50â†’120m ë™ì‹œ curriculum ì§„í–‰
#   í•´ê²°: ì„ê³„ê°’ ë¶„ë¦¬ (NPC: -1.5, goal: -2.5)
#   ì›ì¹™: í•œ ë²ˆì— í•˜ë‚˜ì˜ ì°¨ì›ë§Œ ë‚œì´ë„ ì¦ê°€.
#
# === Curriculum ì„¤ê³„ ì›ì¹™ ===
#
# 1. ì ì§„ì  ë„ì…: 0â†’1â†’2â†’4 (í•œ ë²ˆì— 2ë°° ì´í•˜ ì¦ê°€)
# 2. ì„ê³„ê°’ ë¶„ë¦¬: ê° í™˜ê²½ ë³€ìˆ˜ì˜ thresholdë¥¼ ë‹¤ë¥´ê²Œ ì„¤ì •
# 3. min_lesson_length: 300+ (ì¶©ë¶„í•œ í•™ìŠµ ì‹œê°„ ë³´ì¥)
# 4. signal_smoothing: true (ë…¸ì´ì¦ˆ ë°©ì§€)
```

## Task Breakdown

| ID | Task | Priority | Status | Est. Time |
|----|------|----------|--------|-----------|
| **Stage 1: Behavioral Cloning** |
| P5-01 | BC ë°ì´í„° ë¡œë” êµ¬í˜„ | High | âœ… | 2ì¼ |
| P5-02 | BC ë„¤íŠ¸ì›Œí¬ êµ¬í˜„ | High | âœ… | 2ì¼ |
| P5-03 | BC í•™ìŠµ íŒŒì´í”„ë¼ì¸ | High | âœ… | 3ì¼ |
| P5-04 | BC í‰ê°€ ë° íŠœë‹ | High | âœ… | 3ì¼ |
| **Stage 2: Pure RL (Single Area)** |
| P5-05 | PPO Curriculum í•™ìŠµ | High | âœ… | 3ì¼ |
| P5-06 | ë³´ìƒ í•¨ìˆ˜ êµ¬í˜„ | High | âœ… | 2ì¼ |
| P5-07 | Unity í™˜ê²½ ì—°ë™ (PhysX í•´ê²°) | High | âœ… | 3ì¼ |
| P5-08 | PPO 950K+ steps í•™ìŠµ | High | âœ… | 5ì¼ |
| **Stage 3: ë³‘ë ¬ Training Areas** |
| P5-09 | TrainingArea í”„ë¦¬íŒ¹ êµ¬ì„± | High | âœ… | 1ì¼ |
| P5-10 | 16 Areas ë°°ì¹˜ ë° í…ŒìŠ¤íŠ¸ | High | âœ… | 1ì¼ |
| P5-11 | PPO ë³‘ë ¬ í•™ìŠµ (1.66M steps, Reward ~750 ìˆ˜ë ´) | High | âœ… | 1ì¼ |
| P5-12 | SAC ë³‘ë ¬ í•™ìŠµ ë¹„êµ | High | â³ | 1ì¼ |
| **Stage 4: ì†ë„ ì •ì±… (ë„ë¡œêµí†µë²•)** |
| P5-13 | ì†ë„ êµ¬ê°„ ì‹œìŠ¤í…œ êµ¬í˜„ (WaypointManager) | High | âœ… | 1ì¼ |
| P5-14 | ì†ë„ ìœ„ë°˜ Reward êµ¬í˜„ (ì ì§„ì  íŒ¨ë„í‹°) | High | âœ… | 1ì¼ |
| P5-15 | Reward ì¬ì¡°ì • (v7â†’v8: collision, nearCollision, off-road) | High | âœ… | 1ì¼ |
| P5-16 | Observation í™•ì¥ (+4D speed_info, ì´ 242D) | High | âœ… | 1ì¼ |
| P5-17 | Curriculum ì¬ì„¤ê³„ (NPC ì ì§„ì , threshold ë¶„ë¦¬) | High | âœ… | 1ì¼ |
| P5-18 | ì†ë„ ì •ì±… í†µí•© í•™ìŠµ (v8, 3.07M/8M ì§„í–‰ ì¤‘) | High | ğŸ”„ | ì§„í–‰ì¤‘ |
| P5-19 | 32 Areas í™•ì¥ ì ìš© (Stage 4 ì™„ë£Œ í›„) | Medium | â³ | 1ì¼ |
| **Stage 5: Multi-Lane + ì°¨ì„  ì •ì±…** |
| P5-20 | ë‹¤ì°¨ì„  ë„ë¡œ í™˜ê²½ êµ¬ì¶• | High | â³ | 2ì¼ |
| P5-21 | ì°¨ì„  ë§ˆí‚¹ ì‹œìŠ¤í…œ (5ì¢…) | High | â³ | 2ì¼ |
| P5-22 | Raycast ì°¨ì„  ê°ì§€ | High | â³ | 1ì¼ |
| P5-23 | Observation í™•ì¥ (+12D lane_info) | High | â³ | 1ì¼ |
| P5-24 | ì°¨ì„  ìœ„ë°˜ Reward êµ¬í˜„ | High | â³ | 1ì¼ |
| P5-25 | ì°¨ì„ +ì†ë„ ì •ì±… í†µí•© í•™ìŠµ (32 Areas) | High | â³ | 2ì¼ |
| **Stage 6: ë„ë¡œ ë„¤íŠ¸ì›Œí¬ + ê²½ë¡œ ì¶”ì¢… (Navigation)** |
| P5-26 | ë„ë¡œ ê·¸ë˜í”„ ì‹œìŠ¤í…œ (Node/Edge) | High | â³ | 2ì¼ |
| P5-27 | êµì°¨ë¡œ í”„ë¦¬íŒ¹ (Tì/ì‹­ì) | High | â³ | 2ì¼ |
| P5-28 | Route Planner (A*/Dijkstra ê²½ë¡œ ìƒì„±) | High | â³ | 2ì¼ |
| P5-29 | Navigation Command ì‹œìŠ¤í…œ | High | â³ | 1ì¼ |
| P5-30 | Observation í™•ì¥ (+10D navigation) | High | â³ | 1ì¼ |
| P5-31 | ê²½ë¡œ ì¶”ì¢… Reward (route_following, wrong_turn) | High | â³ | 1ì¼ |
| P5-32 | Curriculum (ì§ì„ â†’Tìâ†’ì‹­ìâ†’ë³µí•©) | High | â³ | 2ì¼ |
| P5-33 | ë„ë¡œ ë„¤íŠ¸ì›Œí¬ í†µí•© í•™ìŠµ (32 Areas) | High | â³ | 2ì¼ |
| **Stage 7: Camera Visual Observation (8-16 Areas)** |
| P5-34 | CameraSensorComponent ì¶”ê°€ | High | â³ | 1ì¼ |
| P5-35 | ML-Agents Visual Encoder ì„¤ì • | High | â³ | 1ì¼ |
| P5-36 | Vector+Visual ë³µí•© í•™ìŠµ (16 Areas) | High | â³ | 2ì¼ |
| P5-37 | Camera-only í•™ìŠµ (Level 2 ê²€ì¦) | Medium | â³ | 2ì¼ |
| **Stage 8: Euro NCAP + ì‹ í˜¸ë“± ì¸ì‹** |
| P5-38 | ELK ì‹œë‚˜ë¦¬ì˜¤ êµ¬í˜„ (5ì¢…) | Medium | â³ | 2ì¼ |
| P5-39 | LKA ì‹œë‚˜ë¦¬ì˜¤ êµ¬í˜„ (2ì¢…) | Medium | â³ | 1ì¼ |
| P5-40 | ì‹ í˜¸ë“± ì¸ì‹ í•™ìŠµ (Camera â†’ ì /ë…¹/í™© ë¶„ë¥˜) | Medium | â³ | 2ì¼ |
| P5-41 | DTLE ë©”íŠ¸ë¦­ + í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ | Medium | â³ | 1ì¼ |
| P5-42 | ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¦¬í¬íŠ¸ | Medium | â³ | 1ì¼ |
| **Stage 9: GAIL + Hybrid** |
| P5-43 | Expert ì‹œì—° ë…¹í™” (Camera í¬í•¨) | Medium | â³ | 1ì¼ |
| P5-44 | GAIL í•™ìŠµ (8-16 Areas) | Medium | â³ | 2ì¼ |
| P5-45 | Hybrid BCâ†’RL (CIMRL) | High | â³ | 2ì¼ |
| **Stage 10: Full E2E + Ablation** |
| P5-46 | BEV + Occupancy Network (Level 3) | Medium | â³ | 3ì¼ |
| P5-47 | Temporal Fusion (Level 4) | Medium | â³ | 2ì¼ |
| P5-48 | ë³´ìƒ ìš”ì†Œë³„ ë¶„ì„ | Medium | â³ | 2ì¼ |
| P5-49 | ì•„í‚¤í…ì²˜/í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¶„ì„ | Medium | â³ | 2ì¼ |

## Parallel Training Architecture (Stage 3)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    16x PARALLEL TRAINING AREAS                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Unity Scene (Single Instance)                                          â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚â”‚
â”‚  â”‚  â”‚ Area 0   â”‚ â”‚ Area 1   â”‚ â”‚ Area 2   â”‚ â”‚ Area 3   â”‚   ...x16        â”‚â”‚
â”‚  â”‚  â”‚ Vehicle  â”‚ â”‚ Vehicle  â”‚ â”‚ Vehicle  â”‚ â”‚ Vehicle  â”‚                  â”‚â”‚
â”‚  â”‚  â”‚ Road     â”‚ â”‚ Road     â”‚ â”‚ Road     â”‚ â”‚ Road     â”‚                  â”‚â”‚
â”‚  â”‚  â”‚ 6 NPCs   â”‚ â”‚ 6 NPCs   â”‚ â”‚ 6 NPCs   â”‚ â”‚ 6 NPCs   â”‚                  â”‚â”‚
â”‚  â”‚  â”‚ Lanes    â”‚ â”‚ Lanes    â”‚ â”‚ Lanes    â”‚ â”‚ Lanes    â”‚                  â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚  ê° AreaëŠ” 100m ê°„ê²©ìœ¼ë¡œ ë°°ì¹˜ (ë¬¼ë¦¬ ê°„ì„­ ë°©ì§€)                           â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                            â”‚ 16 agents ë™ì‹œ ìˆ˜ì§‘                             â”‚
â”‚                            â–¼                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  ML-Agents Trainer (PPO/SAC)                                            â”‚â”‚
â”‚  â”‚  batch_size: 4096 (16 areas Ã— 256 time_horizon)                         â”‚â”‚
â”‚  â”‚  buffer_size: 40960                                                     â”‚â”‚
â”‚  â”‚  GPU: RTX 4090 (24GB VRAM) - í™œìš©ë¥  60-80%                              â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                              â”‚
â”‚  ì„±ëŠ¥ ë¹„êµ:                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Config           â”‚ Areas     â”‚ 1M Steps   â”‚ VRAM          â”‚              â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”‚
â”‚  â”‚ Stage 3 (Single) â”‚ 1         â”‚ ~50ë¶„      â”‚ ~2 GB         â”‚              â”‚
â”‚  â”‚ Stage 3 (16x)    â”‚ 16        â”‚ ~3ë¶„       â”‚ ~3.6 GB       â”‚              â”‚
â”‚  â”‚ Stage 4 í˜„ì¬     â”‚ 16        â”‚ ~10ë¶„      â”‚ ~3.6 GB       â”‚              â”‚
â”‚  â”‚ Stage 4 í›„ í™•ì¥  â”‚ 32        â”‚ ~6ë¶„       â”‚ ~8 GB         â”‚              â”‚
â”‚  â”‚ Stage 7 Camera   â”‚ 8-16      â”‚ ~17-30ë¶„   â”‚ ~6-10 GB      â”‚              â”‚
â”‚  â”‚ Phase 6 Sensor   â”‚ 8         â”‚ ~40ë¶„      â”‚ ~14 GB        â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                              â”‚
â”‚  â˜… Stage 4 ì™„ë£Œ í›„: 32 Areas í™•ì¥ (Vector-only)                              â”‚
â”‚  â˜… Camera ì¶”ê°€ ì‹œ: 8-16 Areasë¡œ ì¶•ì†Œ (ë Œë”ë§ ë¶€í•˜)                           â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### TrainingArea êµ¬ì„± (Prefab)
```yaml
TrainingArea (Empty GameObject):
  - E2EDrivingAgent (Vehicle + Agent)
  - Road (ë‹¤ì°¨ì„  ë„ë¡œ)
  - DrivingSceneManager (NPC ìŠ¤í°/ëª©í‘œì  ê´€ë¦¬)
  - LaneMarkings (ì°¨ì„  ë§ˆí‚¹ ì‹œìŠ¤í…œ)
  - NPCVehicles (ìƒëŒ€ ì°¨ëŸ‰)
  - GoalPoint (ëª©í‘œ ì§€ì )
```

### ë³‘ë ¬ í•™ìŠµ Config (v8 í˜„ì¬)
```yaml
# vehicle_ppo_curriculum_parallel.yaml (curriculum_v8_gradual)
behaviors:
  E2EDrivingAgent:
    trainer_type: ppo
    hyperparameters:
      batch_size: 4096         # 16 areas Ã— 256 time_horizon
      buffer_size: 40960
      learning_rate: 3.0e-4
      beta: 5.0e-3
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 5
      learning_rate_schedule: linear
    network_settings:
      normalize: false
      hidden_units: 512
      num_layers: 3
    max_steps: 8000000         # v8: 5Mâ†’8M (ìˆ˜ë ´ ì‹œê°„ í™•ë³´)
    time_horizon: 256
    summary_freq: 10000
    threaded: false

# Curriculum (v8 ì¬ì„¤ê³„: ì ì§„ì  + ë¶„ë¦¬ëœ ì„ê³„ê°’)
environment_parameters:
  num_active_npcs:            # 0â†’1â†’2â†’4 (ì ì§„ì  NPC ë„ì…)
    curriculum:
      - {name: Lesson0, threshold: -1.5, value: 0.0}  # ë¬´êµí†µ
      - {name: Lesson1, threshold: -1.0, value: 1.0}  # NPC 1ëŒ€
      - {name: Lesson2, threshold: 0.0, value: 2.0}   # NPC 2ëŒ€
      - {name: Lesson3, value: 4.0}                    # NPC 4ëŒ€
  goal_distance:              # 50â†’100â†’160â†’230 (ì¤‘ê°„ ë‹¨ê³„ ì¶”ê°€)
    curriculum:
      - {name: Short, threshold: -2.5, value: 50.0}
      - {name: Medium, threshold: -1.5, value: 100.0}
      - {name: Long, threshold: -0.5, value: 160.0}
      - {name: Full, value: 230.0}
  speed_zone_count:           # 1â†’2â†’3â†’4 (ì†ë„ êµ¬ê°„ ì ì§„ ì¶”ê°€)
    curriculum:
      - {name: Single, threshold: 0.0, value: 1.0}
      - {name: Two, threshold: 1.0, value: 2.0}
      - {name: Three, threshold: 2.0, value: 3.0}
      - {name: Four, value: 4.0}

env_settings:
  timeout_wait: 600            # v8: 300â†’600 (Unity ì‘ë‹µ ëŒ€ê¸°)

# â˜… Stage 4 ì™„ë£Œ í›„ 32 Areas í™•ì¥ ì‹œ:
#   batch_size: 8192
#   buffer_size: 81920
#   num_areas: 32 (Unity Sceneì—ì„œ ë³µì œ)
```

---

## Multi-Lane & Lane Policy Design (Stage 4)

### ë„ë¡œ êµ¬ì¡°
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MULTI-LANE ROAD                           â”‚
â”‚                                                                   â”‚
â”‚  â†â† ë°˜ëŒ€í¸ ì°¨ë¡œ (NPC ì—­ì£¼í–‰)                                      â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” (ì´ì¤‘ í™©ìƒ‰ ì‹¤ì„ ) â”‚
â”‚  â†’ 1ì°¨ë¡œ (ì£¼í–‰ ì°¨ë¡œ)  â† Ego Vehicle                               â”‚
â”‚  â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ (ë°±ìƒ‰ ì ì„ )    â”‚
â”‚  â†’ 2ì°¨ë¡œ (ì¶”ì›” ì°¨ë¡œ)                                               â”‚
â”‚  â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬ (ë°±ìƒ‰ ì‹¤ì„ )    â”‚
â”‚  [ê°“ê¸¸/ë„ë¡œ ê²½ê³„]                                                  â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì°¨ì„  ë§ˆí‚¹ ì‹œìŠ¤í…œ (Unity êµ¬í˜„)
```yaml
LaneMarking Types:
  WHITE_DASHED:        # ë°±ìƒ‰ ì ì„  - ì°¨ì„  ë³€ê²½ í—ˆìš©
    material: white, dashed pattern
    layer: "LaneDashed"
    penalty: 0 (í—ˆìš©)

  WHITE_SOLID:         # ë°±ìƒ‰ ì‹¤ì„  - ì°¨ì„  ë³€ê²½ ê¸ˆì§€
    material: white, solid
    layer: "LaneSolid"
    penalty: -2.0

  YELLOW_DASHED:       # í™©ìƒ‰ ì ì„  - ì¤‘ì•™ì„  (ì¶”ì›” ê°€ëŠ¥)
    material: yellow, dashed pattern
    layer: "CenterDashed"
    penalty: -3.0

  YELLOW_SOLID:        # í™©ìƒ‰ ì‹¤ì„  - ì¤‘ì•™ì„  (ì¶”ì›” ê¸ˆì§€)
    material: yellow, solid
    layer: "CenterSolid"
    penalty: -5.0

  DOUBLE_YELLOW_SOLID: # ì´ì¤‘ í™©ìƒ‰ ì‹¤ì„  - ì ˆëŒ€ ê¸ˆì§€
    material: yellow, double solid
    layer: "CenterDouble"
    penalty: -10.0 (collision-level)

Detection Method:
  - ì°¨ëŸ‰ í•˜ë‹¨ ì¢Œ/ìš°ì—ì„œ ìˆ˜ì§ Raycast
  - Raycast Hitì˜ Layer/Tagë¡œ ì°¨ì„  ìœ í˜• íŒë³„
  - ì°¨ì„  ì¤‘ì•™ offset ê³„ì‚°
```

### í™•ì¥ëœ Observation Space (Lane + Speed aware)
```yaml
# Total: ~156 dimensions (ê¸°ì¡´ 140D + lane_info 12D + speed_info 4D)

ego_state: 8D            # (ê¸°ì¡´)
route_info: 30D           # (ê¸°ì¡´)
surrounding: 40D          # (ê¸°ì¡´)
bev_features: 64D         # (ê¸°ì¡´, optional)

lane_info: 12D            # â† NEW (Stage 4)
  - left_lane_dist: 1D         # ì¢Œì¸¡ ì°¨ì„  ê²½ê³„ê¹Œì§€ ê±°ë¦¬ (m)
  - right_lane_dist: 1D        # ìš°ì¸¡ ì°¨ì„  ê²½ê³„ê¹Œì§€ ê±°ë¦¬ (m)
  - left_lane_type: 4D         # one-hot [ì ì„ , ë°±ì‹¤ì„ , í™©ì ì„ , í™©ì‹¤ì„ ]
  - right_lane_type: 4D        # one-hot
  - center_offset: 1D          # í˜„ì¬ ì°¨ì„  ì¤‘ì•™ ëŒ€ë¹„ offset (m)
  - heading_error: 1D          # ì°¨ì„  ë°©í–¥ ëŒ€ë¹„ heading ì˜¤ì°¨ (rad)

speed_info: 4D            # â† NEW (Stage 4)
  - current_speed_norm: 1D     # í˜„ì¬ ì†ë„ / max_speed (ì •ê·œí™”)
  - speed_limit_norm: 1D       # êµ¬ê°„ ì œí•œì†ë„ / max_speed (ì •ê·œí™”)
  - speed_ratio: 1D            # current_speed / speed_limit (1.0ì´ ì ì •)
  - next_speed_limit_norm: 1D  # ë‹¤ìŒ êµ¬ê°„ ì œí•œì†ë„ (ì‚¬ì „ ê°ì† ìœ ë„)
```

### í™•ì¥ëœ Reward Function (Lane-aware)
```yaml
# === ê¸°ì¡´ Reward (ìœ ì§€) ===
progress: +1.0
goal_reached: +10.0
collision: -10.0
near_collision: -0.5
off_road: -5.0
jerk: -0.1

# === NEW: ì°¨ì„  ì •ì±… Reward ===
lane_keeping: +0.3
  description: "ì°¨ì„  ì¤‘ì•™ ìœ ì§€ ë³´ë„ˆìŠ¤"
  formula: "+0.3 * max(0, 1 - |center_offset| / lane_width)"

lane_violation_white_solid: -2.0
  description: "ë°±ìƒ‰ ì‹¤ì„  ìœ„ë°˜"
  condition: "crossed WHITE_SOLID marking"

lane_violation_yellow_dashed: -3.0
  description: "í™©ìƒ‰ ì ì„  ì¤‘ì•™ì„  ì¹¨ë²”"
  condition: "crossed YELLOW_DASHED center line"

lane_violation_yellow_solid: -5.0
  description: "í™©ìƒ‰ ì‹¤ì„  ì¤‘ì•™ì„  ì¹¨ë²”"
  condition: "crossed YELLOW_SOLID center line"

lane_violation_double_yellow: -10.0
  description: "ì´ì¤‘ í™©ìƒ‰ ì‹¤ì„  ì¹¨ë²” (ì¹˜ëª…ì )"
  condition: "crossed DOUBLE_YELLOW marking"
  terminates: true

lane_change_signal: +0.5
  description: "ì ì ˆí•œ ì°¨ì„  ë³€ê²½ (ì ì„ ì—ì„œë§Œ)"
  condition: "changed lane through WHITE_DASHED"

# === NEW: ì†ë„ ì •ì±… Reward ===
speed_compliance: +0.3
  description: "ì ì • ì†ë„ ìœ ì§€ ë³´ìƒ (ì œí•œì†ë„ì˜ 80-100%)"
  formula: "+0.3 if 0.8*speed_limit <= speed <= speed_limit"

speed_over_limit: -0.5 ~ -3.0
  description: "ì œí•œì†ë„ ì´ˆê³¼ ì ì§„ì  íŒ¨ë„í‹°"
  formula: |
    over_ratio = (speed - speed_limit) / speed_limit
    penalty = -0.5 * min(over_ratio * 10, 6.0)
    # 10% ì´ˆê³¼ â†’ -0.5, 20% â†’ -1.0, 50%+ â†’ -3.0 (cap)

speed_zone_transition: +0.2
  description: "ì†ë„ êµ¬ê°„ ì§„ì… ì‹œ ì ì ˆí•œ ê°ì†/ê°€ì†"
  condition: "smooth speed change within 5s of zone boundary"
  formula: "+0.2 * (1 - |target_speed - actual_speed| / target_speed)"

speed_under_limit: -0.1
  description: "ì§€ë‚˜ì¹˜ê²Œ ëŠë¦° ì£¼í–‰ (êµí†µ ë°©í•´)"
  condition: "speed < 0.5 * speed_limit AND no obstacle ahead"
```

---

## Speed Limit Policy Design (Stage 4 í™•ì¥)

### ì†ë„ êµ¬ê°„ ì„¤ê³„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SPEED ZONE LAYOUT                                      â”‚
â”‚                                                                               â”‚
â”‚  Z=-200          Z=-100           Z=0             Z=100           Z=230       â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”‚
â”‚  â”‚   30 km/h      â”‚   50 km/h      â”‚   60 km/h      â”‚   80 km/h     â”‚        â”‚
â”‚  â”‚  (ì£¼ê±°êµ¬ê°„)    â”‚  (ì‹œê°€ì§€êµ¬ê°„)   â”‚  (ì¼ë°˜ë„ë¡œ)    â”‚  (ìë™ì°¨ì „ìš©)  â”‚        â”‚
â”‚  â”‚                â”‚                â”‚                â”‚               â”‚        â”‚
â”‚  â”œâ”€ ê°ì†í‘œì§€ â”€â”€â”€â”€â”€â”¼â”€ ì†ë„ë³€ê²½ â”€â”€â”€â”€â”€â”¼â”€ ì†ë„ë³€ê²½ â”€â”€â”€â”€â”€â”¼â”€ ê°€ì†í—ˆìš© â”€â”€â”€â”€â”¤        â”‚
â”‚                                                                               â”‚
â”‚  â† Ego ì¶œë°œ (Z=-200)                                    Goal (Z=230) â†’       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### í•œêµ­ ë„ë¡œêµí†µë²• ê¸°ë°˜ ì†ë„ ê·œì •

```yaml
SpeedZone Types:
  RESIDENTIAL:          # ì£¼ê±°ì§€ì—­/ì–´ë¦°ì´ë³´í˜¸êµ¬ì—­
    limit: 30 km/h (8.3 m/s)
    tolerance: +10 km/h (í•œêµ­ ê³¼ì† ë‹¨ì† ì—¬ìœ )
    penalty_start: 40 km/h

  URBAN_NARROW:         # ì‹œê°€ì§€ ì´ë©´ë„ë¡œ
    limit: 50 km/h (13.9 m/s)
    tolerance: +10 km/h
    penalty_start: 60 km/h

  URBAN_GENERAL:        # ì¼ë°˜ë„ë¡œ (ë„ì‹œë¶€)
    limit: 60 km/h (16.7 m/s)
    tolerance: +10 km/h
    penalty_start: 70 km/h

  EXPRESSWAY:           # ìë™ì°¨ì „ìš©ë„ë¡œ
    limit: 80 km/h (22.2 m/s)
    tolerance: +10 km/h
    penalty_start: 90 km/h

  HIGHWAY:              # ê³ ì†ë„ë¡œ
    limit: 100-110 km/h (27.8-30.6 m/s)
    tolerance: +10 km/h
    penalty_start: 120 km/h

  VARIABLE:             # ê°€ë³€ì†ë„ êµ¬ê°„ (ê³µì‚¬/ì‚¬ê³ )
    limit: dynamic (í‘œì§€íŒ ê¸°ë°˜)
    tolerance: 0 km/h
```

### WaypointManager ì†ë„ íƒœê·¸ ì‹œìŠ¤í…œ

```yaml
# ê° ì›¨ì´í¬ì¸íŠ¸ì— ì†ë„ êµ¬ê°„ ì •ë³´ íƒœê·¸
Waypoint:
  position: [x, y, z]
  speed_limit: float (m/s)        # í•´ë‹¹ êµ¬ê°„ ì œí•œì†ë„
  zone_type: enum                  # RESIDENTIAL / URBAN / EXPRESSWAY / etc.
  is_zone_boundary: bool           # ì†ë„ ë³€ê²½ êµ¬ê°„ ì‹œì‘ì  ì—¬ë¶€
  deceleration_warning: float      # ê°ì† í•„ìš” ê±°ë¦¬ (m) - ì‚¬ì „ ê²½ê³ 

# Curriculum ì—°ë™:
#   Lesson 0-1: ë‹¨ì¼ ì†ë„ êµ¬ê°„ (60 km/h)
#   Lesson 2:   2ê°œ êµ¬ê°„ (60 â†’ 80 km/h)
#   Lesson 3:   4ê°œ êµ¬ê°„ (30 â†’ 50 â†’ 60 â†’ 80 km/h)
```

### ì†ë„ ìœ„ë°˜ íŒ¨ë„í‹° êµ¬ì¡° (í•œêµ­ë²• ê¸°ì¤€)

```yaml
# í•œêµ­ ë„ë¡œêµí†µë²• ì œ17ì¡° ê¸°ë°˜ íŒ¨ë„í‹° ìŠ¤ì¼€ì¼ë§
penalty_scale:
  over_10kmh:   -0.5    # ê²½ë¯¸í•œ ìœ„ë°˜ (ë²”ì¹™ê¸ˆ 3ë§Œì›)
  over_20kmh:   -1.0    # ì¼ë°˜ ìœ„ë°˜ (ë²”ì¹™ê¸ˆ 6ë§Œì›)
  over_40kmh:   -2.0    # ì¤‘ëŒ€ ìœ„ë°˜ (ë²”ì¹™ê¸ˆ 9ë§Œì› + ë²Œì )
  over_60kmh:   -3.0    # ìœ„í—˜ ìš´ì „ (ë²”ì¹™ê¸ˆ 12ë§Œì› + ë©´í—ˆì •ì§€)
  over_80kmh:   -5.0    # ê·¹ì‹¬í•œ ìœ„ë°˜ (í˜•ì‚¬ì²˜ë²Œ ê°€ëŠ¥)

# ìµœì €ì†ë„ ìœ„ë°˜ (ê³ ì†ë„ë¡œ):
#   limit: 50 km/h ì´ìƒ ìœ ì§€ ì˜ë¬´
#   under_minimum: -0.5 (êµí†µ ë°©í•´)

# ê°€ê°ì† êµ¬ê°„:
#   zone_boundary ì ‘ê·¼ ì‹œ:
#   - ê°ì† êµ¬ê°„: 100m ì „ ê°ì† ì‹œì‘ ì‹œ ë³´ìƒ
#   - ê¸‰ê°ì†: jerk > 3 m/sÂ³ ì‹œ ì¶”ê°€ íŒ¨ë„í‹°
```

### Observation ì¸ì½”ë”©

```yaml
# Agentê°€ ì†ë„ ì œí•œì„ ì¸ì‹í•˜ëŠ” ë°©ë²•:
speed_info (4D):
  current_speed_norm:     # ego_speed / max_speed â†’ [0, 1]
  speed_limit_norm:       # zone_limit / max_speed â†’ [0, 1]
  speed_ratio:            # ego_speed / zone_limit â†’ 0.8~1.0ì´ ì ì •
  next_speed_limit_norm:  # ë‹¤ìŒ êµ¬ê°„ ì œí•œì†ë„ (ê°ì† ìœ ë„)

# ì†ë„ í‘œì§€íŒ ì¸ì‹ (visual cue):
#   - ì‹¤ì œ Vision ê¸°ë°˜: Perception ëª¨ë¸ ì¶œë ¥ ì‚¬ìš© (Phase 3)
#   - í˜„ì¬ ë‹¨ê³„: WaypointManagerì—ì„œ ì§ì ‘ ì œê³µ (ground truth)
```

### êµ¬í˜„ ìš°ì„ ìˆœìœ„

```
Priority 1: ë‹¨ì¼ ì œí•œì†ë„ (60 km/h) + over/under penalty
Priority 2: êµ¬ê°„ë³„ ì†ë„ ë³€ê²½ (2-4 zones)
Priority 3: ê°ì† êµ¬ê°„ smooth transition reward
Priority 4: ì»¤ë¦¬í˜ëŸ¼ ì—°ë™ (ì ì§„ì  êµ¬ê°„ ì¶”ê°€)
```

---

## Road Network & Route Following Design (Stage 6)

### ì‹¤ì œ ììœ¨ì£¼í–‰ Navigation êµ¬ì¡°

```
ì‹¤ì œ ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œ:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. ëª©ì ì§€ ì„¤ì • (ì‚¬ìš©ì ì…ë ¥)                                    â”‚
â”‚     â†“                                                          â”‚
â”‚  2. Global Planning (A*/Dijkstra)                               â”‚
â”‚     ë„ë¡œ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ì—ì„œ ìµœë‹¨/ìµœì  ê²½ë¡œ íƒìƒ‰                   â”‚
â”‚     â†“                                                          â”‚
â”‚  3. Route = [Edge1, Edge2, Edge3, ...] (í†µê³¼í•  ë„ë¡œ êµ¬ê°„ ë¦¬ìŠ¤íŠ¸)  â”‚
â”‚     â†“                                                          â”‚
â”‚  4. Local Planning (RL/IL Agent)                                â”‚
â”‚     ê²½ë¡œë¥¼ ë”°ë¼ ì£¼í–‰ + ì¥ì• ë¬¼ íšŒí”¼ + êµí†µ ê·œì¹™ ì¤€ìˆ˜                â”‚
â”‚     êµì°¨ë¡œì—ì„œ navigation commandì— ë”°ë¼ ì¢Œ/ìš°íšŒì „/ì§ì§„            â”‚
â”‚     â†“                                                          â”‚
â”‚  5. ëª©ì ì§€ ë„ì°©                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### í˜„ì¬ êµ¬í˜„ vs ëª©í‘œ

```
í˜„ì¬ (Stage 3):
  - ì§ì„  ë„ë¡œ 1ê°œ (500m)
  - ì›¨ì´í¬ì¸íŠ¸: Zì¶• ì¼ì§ì„  ë°°ì¹˜ (laneX=1.75 ê³ ì •)
  - êµì°¨ë¡œ ì—†ìŒ, íšŒì „ ì—†ìŒ
  - ì—ì´ì „íŠ¸: "ì•ìœ¼ë¡œ ê°€ë©´ì„œ ì¥ì• ë¬¼ í”¼í•˜ê¸°"

ëª©í‘œ (Stage 6):
  - Tì/ì‹­ì êµì°¨ë¡œ í¬í•¨ ë„ë¡œ ë„¤íŠ¸ì›Œí¬
  - ê·¸ë˜í”„ ê¸°ë°˜ ê²½ë¡œ ìƒì„± (Node=êµì°¨ë¡œ, Edge=ë„ë¡œêµ¬ê°„)
  - ì—ì´ì „íŠ¸: navigation commandë¥¼ ë”°ë¼ ëª©ì ì§€ê¹Œì§€ ì£¼í–‰
  - Curriculum: ì§ì„  â†’ Tì 1ê°œ â†’ ì‹­ì 1ê°œ â†’ ë³µí•© (3-4êµì°¨ë¡œ)
```

### ë„ë¡œ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„

```
                    [Node 2]
                       â”‚
                    Edge_N (50m)
                       â”‚
[Node 0] â”€â”€Edge_W(100m)â”€â”€[Node 1]â”€â”€Edge_E(100m)â”€â”€[Node 3]
                       â”‚
                    Edge_S (50m)
                       â”‚
                    [Node 4]

Node = êµì°¨ë¡œ (Intersection)
  - position: Vector3
  - type: Tì / ì‹­ì / ë¡œí„°ë¦¬
  - connected_edges: List<Edge>
  - traffic_light: optional

Edge = ë„ë¡œ êµ¬ê°„ (RoadSegment)
  - start_node, end_node: Node
  - length: float (m)
  - speed_limit: float (m/s)
  - num_lanes: int
  - lane_markings: LaneMarkingType[]
  - waypoints: List<Vector3> (ì¤‘ê°„ ê²½ìœ ì , ê³¡ì„  ë„ë¡œ ì§€ì›)
  - direction: bidirectional / one-way
```

### Route Planner (ê²½ë¡œ ìƒì„±)

```csharp
// RoadNetworkManager.cs
public class RoadNetworkManager : MonoBehaviour
{
    public List<IntersectionNode> nodes;
    public List<RoadEdge> edges;

    /// <summary>
    /// A* ê¸°ë°˜ ìµœë‹¨ ê²½ë¡œ íƒìƒ‰
    /// </summary>
    public List<RoadEdge> FindRoute(IntersectionNode start, IntersectionNode goal)
    {
        // A* with distance heuristic
        // Returns ordered list of edges to traverse
    }

    /// <summary>
    /// ê²½ë¡œë¥¼ ë”°ë¼ ì›¨ì´í¬ì¸íŠ¸ ìƒì„± (ê³¡ì„  í¬í•¨)
    /// </summary>
    public List<Vector3> GenerateRouteWaypoints(List<RoadEdge> route)
    {
        // ê° Edgeì˜ waypointsë¥¼ ì—°ê²°
        // êµì°¨ë¡œì—ì„œëŠ” turning path ì¶”ê°€ (Bezier curve)
    }
}
```

### Navigation Command ì‹œìŠ¤í…œ

```yaml
NavigationCommand (6D one-hot):
  GO_STRAIGHT: [1,0,0,0,0,0]    # ì§ì§„ (ê¸°ë³¸)
  TURN_LEFT:   [0,1,0,0,0,0]    # ì¢ŒíšŒì „
  TURN_RIGHT:  [0,0,1,0,0,0]    # ìš°íšŒì „
  U_TURN:      [0,0,0,1,0,0]    # ìœ í„´
  LANE_LEFT:   [0,0,0,0,1,0]    # ì¢Œì°¨ì„  ë³€ê²½
  LANE_RIGHT:  [0,0,0,0,0,1]    # ìš°ì°¨ì„  ë³€ê²½

Command ë°œí–‰ ê·œì¹™:
  - êµì°¨ë¡œ 50m ì „: ë‹¤ìŒ ë°©í–¥ command ë°œí–‰
  - ì§ì„  êµ¬ê°„: GO_STRAIGHT ìœ ì§€
  - ì°¨ì„  ë³€ê²½ í•„ìš” ì‹œ: 100m ì „ LANE_LEFT/RIGHT ë°œí–‰
  - êµì°¨ë¡œ í†µê³¼ í›„: GO_STRAIGHTë¡œ ë³µê·€

IntersectionInfo (4D):
  - distance_to_intersection:  # 0~1 (50m ê¸°ì¤€ ì •ê·œí™”)
  - intersection_type:         # T=0.33, Cross=0.67, Rotary=1.0
  - entry_angle:               # ì§„ì… ë°©í–¥ (-1~1, normalized)
  - exit_angle:                # ì¶œêµ¬ ë°©í–¥ (-1~1, normalized)
```

### êµì°¨ë¡œ ë¬¼ë¦¬ í™˜ê²½

```yaml
IntersectionPrefab:
  Components:
    - IntersectionNode: ê·¸ë˜í”„ ë…¸ë“œ ì •ë³´
    - TriggerZone: êµì°¨ë¡œ ì§„ì…/ì¶œêµ¬ ê°ì§€ (BoxCollider, trigger)
    - TrafficLight: ì‹ í˜¸ë“± (ì„ íƒì , Stage 6+)
    - TurnGuide: íšŒì „ ê²½ë¡œ ê°€ì´ë“œ (Bezier ê³¡ì„  waypoints)

  Layout (ì‹­ì êµì°¨ë¡œ):
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              â”‚ â†‘ â”‚ â†“ â”‚                â”‚
    â”‚              â”‚   â”‚   â”‚                â”‚
    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚   â† â†       â”‚       â”‚       â†’ â†’      â”‚
    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚              â”‚   â”‚   â”‚                â”‚
    â”‚              â”‚ â†‘ â”‚ â†“ â”‚                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  TurnPath (ì¢ŒíšŒì „ ì˜ˆì‹œ):
    - ì§„ì…: ì§ì§„ â†’ êµì°¨ë¡œ ì¤‘ì‹¬ ì ‘ê·¼
    - íšŒì „: Bezier curve (control pointsë¡œ ë¶€ë“œëŸ¬ìš´ ê³¡ì„ )
    - ì¶œêµ¬: íšŒì „ ì™„ë£Œ â†’ ìƒˆ ë„ë¡œ ì§ì§„
```

### Reward í™•ì¥ (Navigation)

```yaml
# === Route Following Rewards ===
route_following: +0.5
  description: "ê²½ë¡œ ìœ„ ì£¼í–‰ ë³´ë„ˆìŠ¤"
  formula: "+0.5 * max(0, 1 - route_deviation / max_deviation)"
  note: "ê²½ë¡œì—ì„œ ë²—ì–´ë‚ ìˆ˜ë¡ ë³´ìƒ ê°ì†Œ"

correct_turn: +5.0
  description: "êµì°¨ë¡œì—ì„œ ì˜¬ë°”ë¥¸ ë°©í–¥ ì§„ì…"
  condition: "entered correct exit edge per navigation command"

wrong_turn: -5.0
  description: "êµì°¨ë¡œì—ì„œ ì˜ëª»ëœ ë°©í–¥ ì§„ì…"
  condition: "entered wrong exit edge"
  note: "ì—í”¼ì†Œë“œ ì¢…ë£Œí•˜ì§€ ì•ŠìŒ (ì¬íƒìƒ‰ ê°€ëŠ¥ì„±)"

missed_turn: -3.0
  description: "êµì°¨ë¡œë¥¼ ê·¸ëƒ¥ í†µê³¼ (íšŒì „ ì‹¤íŒ¨)"
  condition: "passed through intersection without turning when commanded"

destination_reached: +20.0
  description: "ìµœì¢… ëª©ì ì§€ ë„ë‹¬"
  condition: "distance_to_final_goal < 5.0m"
  terminates: true

intersection_speed: +0.2
  description: "êµì°¨ë¡œ ì§„ì… ì‹œ ì ì • ê°ì†"
  condition: "speed <= intersection_speed_limit at trigger zone"
  note: "êµì°¨ë¡œ ë‚´ ì œí•œì†ë„ 30km/h"
```

### Curriculum Learning (Navigation)

```yaml
environment_parameters:
  road_complexity:
    curriculum:
      - name: Lesson0_Straight
        completion_criteria:
          measure: reward
          threshold: 0.0
          min_lesson_length: 200
        value: 0.0       # ì§ì„  ë„ë¡œë§Œ

      - name: Lesson1_TSingle
        completion_criteria:
          measure: reward
          threshold: 3.0
          min_lesson_length: 200
        value: 1.0       # Tì êµì°¨ë¡œ 1ê°œ (ì¢Œ/ìš°íšŒì „)

      - name: Lesson2_CrossSingle
        completion_criteria:
          measure: reward
          threshold: 5.0
          min_lesson_length: 200
        value: 2.0       # ì‹­ì êµì°¨ë¡œ 1ê°œ (4ë°©í–¥)

      - name: Lesson3_Network
        value: 3.0       # ë³µí•© ë„¤íŠ¸ì›Œí¬ (3-4ê°œ êµì°¨ë¡œ)

  num_route_choices:
    curriculum:
      - name: SingleRoute
        completion_criteria:
          measure: reward
          threshold: 0.0
        value: 1.0       # ê²½ë¡œ 1ê°œ (ë¬´ì¡°ê±´ ë”°ë¼ê°€ê¸°)

      - name: MultiRoute
        value: 3.0       # ë™ì¼ ì¶œë°œ/ë„ì°©, 3ê°œ ê²½ë¡œ ì¤‘ ëœë¤ ì„ íƒ
```

### êµ¬í˜„ ìš°ì„ ìˆœìœ„

```
Priority 1: ì§ì„  + Tì êµì°¨ë¡œ 1ê°œ (ì¢Œ/ìš°íšŒì „ë§Œ)
  - IntersectionNode, RoadEdge í´ë˜ìŠ¤ ì •ì˜
  - NavigationCommand observation ì¶”ê°€
  - correct_turn / wrong_turn reward
  - Curriculum Lesson0-1

Priority 2: ì‹­ì êµì°¨ë¡œ (4ë°©í–¥)
  - 4 exit edges
  - TurnGuide (Bezier curve paths)
  - Lesson2

Priority 3: ë³µí•© ë„¤íŠ¸ì›Œí¬ (3-4 êµì°¨ë¡œ)
  - A* Route Planner
  - ë‹¤ìˆ˜ ê²½ë¡œ ì¤‘ ì„ íƒ
  - Lesson3

Priority 4: ì‹ í˜¸ë“± + ëŒ€ê¸°
  - TrafficLight ì»´í¬ë„ŒíŠ¸
  - ì ìƒ‰ ëŒ€ê¸°, ë…¹ìƒ‰ ì¶œë°œ reward
  - intersection_wait: -0.05/step (ë¶ˆí•„ìš” ëŒ€ê¸° ì‹œ íŒ¨ë„í‹°)
```

---

## Camera Visual Observation Design (Stage 7)

### ML-Agents CameraSensor í†µí•©

```yaml
# Agentì— CameraSensorComponent ì¶”ê°€
CameraSensor:
  camera: Front-facing camera (84x84 RGB)
  sensor_name: "FrontCamera"
  compression_type: PNG
  observation_stacks: 3    # 3 í”„ë ˆì„ ìŠ¤íƒ (temporal info)

# ML-Agents Config í™•ì¥
network_settings:
  normalize: false
  hidden_units: 512
  num_layers: 3
  vis_encode_type: nature_cnn    # or resnet
  # nature_cnn: 3 conv layers â†’ 512D â†’ concat with vector obs
  # resnet: ResNet-18 encoder â†’ 512D

# VRAM ì˜ˆìƒ:
#   Vector only: ~3.6 GB
#   + Camera (84x84, 16 agents): ~8-12 GB
#   RTX 4090 24GB: ì¶©ë¶„
```

### Level 2 í•™ìŠµ ì „ëµ

```
Phase 1: Vector + Camera ë³µí•© ì…ë ¥
  - ê¸°ì¡´ vector obs (170D) ìœ ì§€
  - Camera 84x84 ì¶”ê°€ (CNN â†’ 128D embedding)
  - ì´ ì…ë ¥: 170D vector + 128D visual = 298D
  - ëª©ì : Cameraê°€ vector obsë¥¼ ë³´ì¡°í•˜ëŠ”ì§€ í™•ì¸

Phase 2: Camera ë¹„ì¤‘ ì¦ê°€
  - vector obsì—ì„œ surrounding(40D) ì œê±°
  - Cameraë¡œ ì£¼ë³€ ì°¨ëŸ‰ ì¸ì‹í•˜ë„ë¡ ìœ ë„
  - ì´: 130D vector + 128D visual

Phase 3: Camera-dominant
  - vector obs: ego_state(8D) + navigation(10D) + speed(4D) = 22D
  - Camera: 128D (ì£¼ë³€ í™˜ê²½ ì „ì²´ ì¸ì‹)
  - ëª©ì : Vision ê¸°ë°˜ ì£¼í–‰ ê²€ì¦
```

### í•™ìŠµ ì„¤ì • ë³€ê²½

```yaml
# vehicle_ppo_camera.yaml
behaviors:
  E2EDrivingAgent:
    trainer_type: ppo
    hyperparameters:
      batch_size: 2048       # camera ë•Œë¬¸ì— ì¤„ì„ (VRAM)
      buffer_size: 20480
      learning_rate: 1.0e-4  # visual encoderëŠ” lr ë‚®ê²Œ
      num_epoch: 3           # overfitting ë°©ì§€
    network_settings:
      normalize: false
      hidden_units: 512
      num_layers: 3
      vis_encode_type: nature_cnn
    max_steps: 10000000      # visionì€ ìˆ˜ë ´ ëŠë¦¼
    time_horizon: 128        # ë©”ëª¨ë¦¬ ì ˆì•½
    summary_freq: 50000
```

---

## Euro NCAP Evaluation Scenarios (Stage 8)

### ELK (Emergency Lane Keeping) ì‹œë‚˜ë¦¬ì˜¤
```yaml
ELK_SolidLine_Left:
  description: "ì¢Œì¸¡ ì‹¤ì„ ìœ¼ë¡œ ì´íƒˆ ì‹œ ìë™ êµì •"
  setup: ego drifts left toward solid line
  pass_criteria: DTLE â‰¤ -0.3m (ì‹¤ì„  ì•ˆìª½ 0.3m ì´ë‚´)
  speed: 72 km/h

ELK_SolidLine_Right:
  description: "ìš°ì¸¡ ì‹¤ì„ ìœ¼ë¡œ ì´íƒˆ ì‹œ ìë™ êµì •"
  setup: ego drifts right toward solid line
  pass_criteria: DTLE â‰¤ -0.3m

ELK_RoadEdge:
  description: "ë„ë¡œ ê²½ê³„ë¡œ ì´íƒˆ ì‹œ êµì •"
  setup: ego drifts toward road edge (no marking)
  pass_criteria: vehicle stays on road

ELK_Oncoming:
  description: "ì¤‘ì•™ì„  ì¹¨ë²” â†’ ì—­ì£¼í–‰ ì¶©ëŒ ë°©ì§€"
  setup: ego drifts into oncoming lane, target approaching at 80 km/h
  pass_criteria: no collision, return to own lane

ELK_Overtaking:
  description: "ë¹„ì˜ë„ì  ì¶”ì›” ì‹œ ì¶©ëŒ ë°©ì§€"
  setup: ego changes lane unintentionally, target in adjacent lane
  lateral_velocity: 0.2-0.6 m/s (unintentional)
  pass_criteria: no collision
```

### LKA (Lane Keeping Assist) ì‹œë‚˜ë¦¬ì˜¤
```yaml
LKA_DashedLine:
  description: "ì ì„  ì´íƒˆ ì‹œ ê²½ê³  + êµì •"
  setup: ego drifts toward dashed line
  pass_criteria: warning issued, correction applied

LKA_SolidLine:
  description: "ì‹¤ì„  ì´íƒˆ ì‹œ êµì •"
  setup: ego drifts toward solid line
  pass_criteria: DTLE â‰¤ -0.3m
```

### í‰ê°€ ë©”íŠ¸ë¦­
```yaml
metrics:
  DTLE: "Distance To Lane Edge (m) - ì°¨ì„  ê²½ê³„ê¹Œì§€ ìµœëŒ€ ì¹¨ë²” ê±°ë¦¬"
  correction_time: "êµì •ì— ì†Œìš”ëœ ì‹œê°„ (s)"
  collision_avoided: "ì¶©ëŒ íšŒí”¼ ì„±ê³µ ì—¬ë¶€ (bool)"
  lane_return_time: "ì›ë˜ ì°¨ì„ ìœ¼ë¡œ ë³µê·€ ì‹œê°„ (s)"
  max_lateral_deviation: "ìµœëŒ€ íš¡ë°©í–¥ ì´íƒˆ (m)"

scoring:
  ELK_score: "sum(scenario_scores) / max_possible"
  LKA_score: "sum(scenario_scores) / max_possible"
  LSS_total: "HMI + LKA + ELK"
```

---

## Algorithm Comparison

| Algorithm | Type | Pros | Cons | Sample Efficiency |
|-----------|------|------|------|-------------------|
| PPO | RL (On-policy) | ì•ˆì •ì , êµ¬í˜„ ì‰¬ì›€ | ìƒ˜í”Œ ë¹„íš¨ìœ¨ | Low |
| SAC | RL (Off-policy) | ìƒ˜í”Œ íš¨ìœ¨, ì—°ì† í–‰ë™ | ë³µì¡ë„ ë†’ìŒ | High |
| TD3 | RL (Off-policy) | SACë³´ë‹¤ ì•ˆì •ì  | - | High |
| BC | IL (Supervised) | ê°„ë‹¨, ë¹ ë¥¸ í•™ìŠµ | Covariate shift | N/A |
| GAIL | IL (GAN-based) | ë³´ìƒ ë¶ˆí•„ìš” | ë¶ˆì•ˆì • ê°€ëŠ¥ | Medium |
| DAgger | IL (Interactive) | Shift í•´ê²° | Expert í•„ìš” | N/A |
| CIMRL | Hybrid | ë‘ ì¥ì  ê²°í•© | ë³µì¡í•œ íŠœë‹ | Medium |

## Hyperparameters

### PPO
```yaml
clip_ratio: 0.2
vf_coef: 0.5
entropy_coef: 0.01
learning_rate: 3e-4
batch_size: 2048
minibatch_size: 64
epochs_per_update: 10
gamma: 0.99
gae_lambda: 0.95
```

### SAC
```yaml
learning_rate: 3e-4
tau: 0.005
gamma: 0.99
buffer_size: 1_000_000
batch_size: 256
auto_entropy: true
```

### BC
```yaml
learning_rate: 1e-4
batch_size: 256
loss: mse  # or nll
epochs: 100
```

## Success Criteria

| Metric | Target | Stage | Notes |
|--------|--------|-------|-------|
| Collision Rate | < 5% | 3+ | Safety-critical |
| Progress Score | > 80% | 3+ | ëª©í‘œ ë°©í–¥ ì§„í–‰ë¥  |
| Comfort Score | > 70% | 3+ | jerk < 2 m/sÂ³ |
| Inference Time | < 50ms | All | Real-time capable |
| **Speed Compliance** | > 90% | 4+ | ì œí•œì†ë„ ì¤€ìˆ˜ìœ¨ (10km/h ì´ë‚´) |
| **Speed Over 20km/h** | < 3% | 4+ | 20km/h ì´ìƒ ì´ˆê³¼ ë¹„ìœ¨ |
| **Zone Transition** | jerk < 2 m/sÂ³ | 4+ | êµ¬ê°„ ì „í™˜ ì‹œ ê¸‰ê°€ê°ì† ë°©ì§€ |
| **Lane Keeping** | DTLE â‰¤ -0.3m | 5+ | Euro NCAP ELK ê¸°ì¤€ |
| **Center Line Violation** | 0% | 5+ | ì´ì¤‘ í™©ìƒ‰ ì‹¤ì„  ì ˆëŒ€ ê¸ˆì§€ |
| **Route Completion** | > 85% | 6+ | ëª©ì ì§€ ë„ë‹¬ ì„±ê³µë¥  |
| **Correct Turn Rate** | > 90% | 6+ | êµì°¨ë¡œ ì˜¬ë°”ë¥¸ ë°©í–¥ ì§„ì… |
| **Wrong Turn Rate** | < 5% | 6+ | ì˜ëª»ëœ ë°©í–¥ ì§„ì… ë¹„ìœ¨ |
| **Navigation Efficiency** | > 80% | 6+ | ìµœë‹¨ ê²½ë¡œ ëŒ€ë¹„ ì‹¤ì œ ê²½ë¡œ íš¨ìœ¨ |
| **Camera Driving Score** | > 70% | 7+ | Vision-only ì£¼í–‰ ì„±ëŠ¥ |
| **ELK Score** | > 70% | 8+ | Euro NCAP ELK ì‹œë‚˜ë¦¬ì˜¤ í†µê³¼ìœ¨ |
| **LKA Score** | > 80% | 8+ | Euro NCAP LKA ì‹œë‚˜ë¦¬ì˜¤ í†µê³¼ìœ¨ |
| **Min Speed (Highway)** | > 50 km/h | 4+ | ìµœì €ì†ë„ ìœ„ë°˜ìœ¨ < 5% |

## Timeline

**ì˜ˆìƒ ì†Œìš”**: 6-8ì£¼

## Dependencies

- Phase 1-4 ì™„ë£Œ
- nuPlan ë°ì´í„°ì…‹ ì ‘ê·¼
- ì¶©ë¶„í•œ GPU ë¦¬ì†ŒìŠ¤ (RTX 4090)

## Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| RL í•™ìŠµ ë¶ˆì•ˆì • | High | Medium | BC ì´ˆê¸°í™” |
| ë³´ìƒ í•¨ìˆ˜ íŠœë‹ ì–´ë ¤ì›€ | High | High | GAIL ëŒ€ì•ˆ |
| ê¸´ í•™ìŠµ ì‹œê°„ | Medium | High | ë³‘ë ¬ í™˜ê²½ |
| Sim-to-Real Gap | Medium | High | Domain Randomization |

## Experiment Tracking

```yaml
# MLflow/W&B Logging

metrics:
  - episode_reward
  - collision_rate
  - progress_score
  - comfort_score (jerk)
  - policy_loss
  - value_loss

artifacts:
  - model checkpoints
  - training curves
  - evaluation videos
  - hyperparameter configs
```

## Deliverables

| # | Deliverable | Stage | Description |
|---|-------------|-------|-------------|
| 1 | **BC Model** | 1 | Expert ë°ì´í„°ë¡œ í•™ìŠµëœ baseline |
| 2 | **PPO/SAC Models** | 2-3 | RLë¡œ í•™ìŠµëœ ì •ì±… (ë³‘ë ¬ 16 Areas, Reward ~750) |
| 3 | **Speed Policy** | 4 | ë„ë¡œêµí†µë²• ê¸°ë°˜ ì†ë„ ì œí•œ ì‹œìŠ¤í…œ |
| 4 | **Multi-Lane Environment** | 5 | ë‹¤ì°¨ì„  ë„ë¡œ + ì°¨ì„  ë§ˆí‚¹ ì‹œìŠ¤í…œ |
| 5 | **Lane Policy** | 5 | 5ì¢… ì°¨ì„  ì¸ì‹ + ìœ„ë°˜ íŒ¨ë„í‹° |
| 6 | **Road Network** | 6 | Tì/ì‹­ì êµì°¨ë¡œ + ë„ë¡œ ê·¸ë˜í”„ ì‹œìŠ¤í…œ |
| 7 | **Route Planner** | 6 | A* ê²½ë¡œ íƒìƒ‰ + Navigation Command |
| 8 | **Navigation Agent** | 6 | ê²½ë¡œ ì¶”ì¢… + êµì°¨ë¡œ íŒë‹¨ ì—ì´ì „íŠ¸ |
| 9 | **Camera Agent** | 7 | Vision-based driving (nature_cnn/resnet) |
| 10 | **Euro NCAP Benchmark** | 8 | ELK/LKA ì‹œë‚˜ë¦¬ì˜¤ í‰ê°€ ê²°ê³¼ |
| 11 | **GAIL Model** | 9 | ë³´ìƒ ì—†ì´ ëª¨ë°© í•™ìŠµëœ ì •ì±… |
| 12 | **Hybrid Model** | 9 | BC + RL fine-tuning ìµœì¢… ëª¨ë¸ |
| 13 | **Full E2E Model** | 10 | BEV + Temporal + Planning í†µí•© |
| 14 | **Ablation Report** | 10 | ì‹¤í—˜ ë¶„ì„ ë³´ê³ ì„œ |
| 15 | **ONNX Models** | All | Unity Sentis ì¶”ë¡ ìš© ëª¨ë¸ |

---

## ğŸ”§ Troubleshooting & Lessons Learned (v12 Training)

### Issue 1: ML-Agents `initialize_from` Path Format

**ìƒí™©**: Phase B í•™ìŠµ ì‹œ Phase A ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì´ˆê¸°í™” ì‹œë„

**ì˜¤ë¥˜ ë©”ì‹œì§€**:
```
UnityTrainerException: Could not initialize from results\results/phase-A_fixed/E2EDrivingAgent.
Make sure models have already been saved with that run ID.
```

**ì›ì¸ ë¶„ì„**:
- ML-AgentsëŠ” `initialize_from`ì— ì§€ì •ëœ ê°’ ì•ì— ìë™ìœ¼ë¡œ `results/`ë¥¼ ë¶™ì„
- ë˜í•œ behavior name (`E2EDrivingAgent`)ë„ ìë™ìœ¼ë¡œ ê²½ë¡œì— ì¶”ê°€í•¨
- YAMLì— `results/phase-A_fixed/E2EDrivingAgent` ì²˜ëŸ¼ ì „ì²´ ê²½ë¡œë¥¼ ì“°ë©´ ì¤‘ë³µ ë°œìƒ

**ì˜ëª»ëœ ì„¤ì •**:
```yaml
# âŒ WRONG - ê²½ë¡œ ì¤‘ë³µ ë°œìƒ
checkpoint_settings:
  initialize_from: results/phase-A_fixed/E2EDrivingAgent
  # ê²°ê³¼: results/results/phase-A_fixed/E2EDrivingAgent/E2EDrivingAgent/checkpoint.pt
```

**ì˜¬ë°”ë¥¸ ì„¤ì •**:
```yaml
# âœ… CORRECT - run_idë§Œ ì§€ì •
checkpoint_settings:
  initialize_from: phase-A_fixed
  # ê²°ê³¼: results/phase-A_fixed/E2EDrivingAgent/checkpoint.pt
```

**í•µì‹¬ ì›ì¹™**:
> `initialize_from`ì—ëŠ” **run_idë§Œ** ì§€ì •. ML-Agentsê°€ `results/` prefixì™€ behavior nameì„ ìë™ ì¶”ê°€í•¨.

---

### Issue 2: BehaviorParameters BehaviorType ë¶ˆì¼ì¹˜

**ìƒí™©**: í•™ìŠµ ì‹œì‘ í›„ 16ê°œ Training Area ì¤‘ ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë§Œ ë§¤ìš° ëŠë¦° ì†ë„ë¡œ ì£¼í–‰ (0.84 m/s vs 15.5 m/s)

**ì¦ìƒ**:
- ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸: ì†ë„ 0.84 m/s, BehaviorParameters í™œì„±í™”
- ë‚˜ë¨¸ì§€ ì—ì´ì „íŠ¸: ì†ë„ 15.5 m/s, BehaviorParameters ë¹„í™œì„±í™” (ML-Agents íŠ¸ë ˆì´ë„ˆì—ì„œ ì œì–´)

**ì›ì¸ ë¶„ì„**:
- BehaviorParameters ì»´í¬ë„ŒíŠ¸ì˜ `BehaviorType` ê°’ ì°¨ì´:
  - `BehaviorType = 0` (Default): ML-Agents íŠ¸ë ˆì´ë„ˆì™€ ì—°ê²°ë˜ì–´ í•™ìŠµ ì°¸ì—¬
  - `BehaviorType = 2` (InferenceOnly): ë¡œì»¬ .onnx ëª¨ë¸ë¡œ ì¶”ë¡ ë§Œ ìˆ˜í–‰ (í•™ìŠµ ë¶ˆì°¸)
- ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ê°€ InferenceOnly ëª¨ë“œë¡œ ì„¤ì •ë˜ì–´ ìˆì–´ ì´ì „ ì²´í¬í¬ì¸íŠ¸ ëª¨ë¸ë¡œ ì¶”ë¡ ë§Œ ì‹¤í–‰

**ë¬¸ì œê°€ ë˜ëŠ” ì„¤ì •**:
```
Agent 1 (ë¬¸ì œ): BehaviorType = 2 (InferenceOnly), Model = "E2EDrivingAgent_phase-B.onnx"
Agent 2-16 (ì •ìƒ): BehaviorType = 0 (Default), Model = null (íŠ¸ë ˆì´ë„ˆ ì œì–´)
```

**í•´ê²° ë°©ë²•**:
1. Unity Inspectorì—ì„œ í•´ë‹¹ ì—ì´ì „íŠ¸ì˜ BehaviorParameters ì»´í¬ë„ŒíŠ¸ í™•ì¸
2. `Behavior Type`ì„ `Default`ë¡œ ë³€ê²½
3. `Model` í•„ë“œë¥¼ ë¹„ì›Œë‘  (íŠ¸ë ˆì´ë„ˆê°€ ì •ì±…ì„ ì œê³µ)

**í™•ì¸ ëª…ë ¹ (Unity MCP)**:
```
manage_components â†’ search_method: by_id â†’ component_type: BehaviorParameters
â†’ Properties: m_BehaviorType, m_Model í™•ì¸
```

**í•µì‹¬ ì›ì¹™**:
> ë³‘ë ¬ í•™ìŠµ ì‹œ **ëª¨ë“  ì—ì´ì „íŠ¸**ì˜ `BehaviorType = 0 (Default)` í•„ìˆ˜. InferenceOnly(2)ëŠ” í‰ê°€/ë°ëª¨ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©.

---

### Issue 3: ì†ë„ íŒ¨ë„í‹° ì¡°ê±´ í—ˆì  (v12 Phase Aì—ì„œ ë°œê²¬)

**ìƒí™©**: ì—ì´ì „íŠ¸ê°€ ì†ë„ 0-1 m/së¡œ ì •ì§€í•˜ì—¬ íŒ¨ë„í‹°ë¥¼ íšŒí”¼

**ì›ì¸ ë¶„ì„**:
```csharp
// âŒ WRONG - speed > 1f ì¡°ê±´ì´ í—ˆì  ìƒì„±
else if (speedRatio < 0.5f && speed > 1f)
{
    reward += speedUnderPenalty;
}
// ì—ì´ì „íŠ¸ê°€ 0-1 m/s ìœ ì§€í•˜ë©´ íŒ¨ë„í‹° ì—†ì´ episode ì§„í–‰
```

**í•´ê²°ì±…**:
```csharp
// âœ… CORRECT - ë¬´ì¡°ê±´ íŒ¨ë„í‹° + ì ì§„ì  ìŠ¤ì¼€ì¼ë§
else if (speedRatio < 0.5f)
{
    float progressivePenalty = speedUnderPenalty * (2f - speedRatio * 2f);
    reward += progressivePenalty;
}
// speedRatio 0%: 2x íŒ¨ë„í‹°, speedRatio 50%: 0x íŒ¨ë„í‹° (ì ì§„ì )
```

**í•µì‹¬ ì›ì¹™**:
> íŒ¨ë„í‹° ì¡°ê±´ì— í—ˆì ì´ ì—†ì–´ì•¼ í•¨. ì¡°ê±´ë¶€ íŒ¨ë„í‹°ëŠ” ì—ì´ì „íŠ¸ê°€ exploití•  ìˆ˜ ìˆëŠ” loopholeì„ ë§Œë“¦.

---

### Checklist: í•™ìŠµ ì‹œì‘ ì „ í™•ì¸ì‚¬í•­

```yaml
# 1. Checkpoint ì´ˆê¸°í™” ê²½ë¡œ í™•ì¸
checkpoint_settings:
  initialize_from: [run_idë§Œ, results/ prefix ì—†ì´]

# 2. Unity Inspector í™•ì¸
All Agents:
  - BehaviorParameters.BehaviorType: Default (0)
  - BehaviorParameters.Model: None/Empty (íŠ¸ë ˆì´ë„ˆ ì‚¬ìš© ì‹œ)

# 3. í•™ìŠµ ì‹œì‘ ìˆœì„œ
1. Unity Editorì—ì„œ Play ë²„íŠ¼ ëˆ„ë¥´ì§€ ì•ŠìŒ
2. mlagents-learn ëª…ë ¹ ì‹¤í–‰
3. "Listening on port 500X" ë©”ì‹œì§€ í™•ì¸
4. Unity Editor Play ë²„íŠ¼ í´ë¦­

# 4. í•™ìŠµ ì¤‘ ëª¨ë‹ˆí„°ë§
- ì²« 1ë¶„: ëª¨ë“  ì—ì´ì „íŠ¸ ì†ë„ ìœ ì‚¬í•œì§€ í™•ì¸
- ì†ë„ í¸ì°¨ í¼: BehaviorType í™•ì¸
- ì—ëŸ¬ ë°œìƒ: read_consoleë¡œ Unity ì½˜ì†” í™•ì¸
```

---

## ğŸ“š Phase ì™„ë£Œ ì‹œ: Obsidian ì§€ì‹í™”

### ì§€ì‹í™” ëŒ€ìƒ
Phase 5 ì™„ë£Œ í›„ ë‹¤ìŒ ë‚´ìš©ì„ Obsidian vaultì— ì •ë¦¬í•©ë‹ˆë‹¤:

| ì¹´í…Œê³ ë¦¬ | ë‚´ìš© |
|----------|------|
| **RL ì•Œê³ ë¦¬ì¦˜** | PPO/SAC êµ¬í˜„ ì„¸ë¶€ì‚¬í•­, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ |
| **IL ì•Œê³ ë¦¬ì¦˜** | BC/GAIL êµ¬í˜„, í•™ìŠµ ì „ëµ |
| **ë³´ìƒ í•¨ìˆ˜** | ë³´ìƒ ì„¤ê³„ ì² í•™, ê° ìš”ì†Œë³„ íš¨ê³¼ ë¶„ì„ |
| **Observation/Action** | ìƒíƒœ/í–‰ë™ ê³µê°„ ì„¤ê³„, ì •ê·œí™” ê¸°ë²• |
| **Hybrid í•™ìŠµ** | BCâ†’RL ì „ì´ í•™ìŠµ, CIMRL ì ìš© |
| **ì‹¤í—˜ ë¶„ì„** | Ablation study ê²°ê³¼, ëª¨ë¸ ë¹„êµ |

### ì‹¤í–‰ ë°©ë²•
```bash
/obsidian sync --phase=5
```

### ìƒì„±ë  ë…¸íŠ¸ êµ¬ì¡°
```
Obsidian Vault/
â”œâ”€â”€ Projects/
â”‚   â””â”€â”€ AD-ML-Platform/
â”‚       â”œâ”€â”€ Phase-5-Planning/
â”‚       â”‚   â”œâ”€â”€ PPO-êµ¬í˜„-ê°€ì´ë“œ.md
â”‚       â”‚   â”œâ”€â”€ SAC-êµ¬í˜„-ê°€ì´ë“œ.md
â”‚       â”‚   â”œâ”€â”€ Behavioral-Cloning.md
â”‚       â”‚   â”œâ”€â”€ GAIL-í•™ìŠµ-ì „ëµ.md
â”‚       â”‚   â”œâ”€â”€ ë³´ìƒ-í•¨ìˆ˜-ì„¤ê³„.md
â”‚       â”‚   â”œâ”€â”€ Hybrid-RL-IL.md
â”‚       â”‚   â”œâ”€â”€ Ablation-Study-ê²°ê³¼.md
â”‚       â”‚   â””â”€â”€ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…-ë¡œê·¸.md
â”‚       â””â”€â”€ ...

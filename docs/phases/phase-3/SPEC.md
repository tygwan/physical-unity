# Phase 3: Perception Models (Simplified)

> βΈοΈ **STATUS: SUSPENDED** - Using Ground Truth approach instead of full perception training
>
> **Reason**: Planning-focused strategy prioritizes RL/IL motion planning. Perception uses direct object info from simulator for faster iteration.

## Overview

Planning μ§‘μ¤‘ μ „λµμ— λ”°λΌ Perceptionμ€ κ°„μ†ν™”ν•μ—¬ κµ¬ν„ν•©λ‹λ‹¤. Pre-trained λ¨λΈ ν™μ© λλ” Ground Truth μ‚¬μ©μ„ μ°μ„ ν•©λ‹λ‹¤.

## Goals

1. **Ground Truth μ¶”μ¶**: μ‹λ®¬λ μ΄μ…μ—μ„ μ§μ ‘ κ°μ²΄ μ •λ³΄ νλ“
2. **Pre-trained λ¨λΈ μ—°λ™**: MMDetection3D λλ” OpenPCDet ν™μ©
3. **BEV Representation**: Bird's Eye View ν‘ν„ μƒμ„±
4. **Planning μ—°λ™**: Perception μ¶λ ¥μ„ Planning μ…λ ¥μΌλ΅ μ—°κ²°

## Strategy

> **Planning μ§‘μ¤‘ μ „λµ**: Perception μμ²΄ κ°λ°μ„ μµμ†ν™”ν•κ³ , κΈ°μ΅΄ λ„κµ¬ ν™μ©

### Approach Options

| Option | Description | Pros | Cons | Priority |
|--------|-------------|------|------|----------|
| A | Ground Truth (Simulation) | μ •ν™•, λΉ λ¦„ | μ‹¤μ  ν™κ²½ λ¶κ°€ | Primary |
| B | Pre-trained Model | μ‹¤μ  μ μ© κ°€λ¥ | μ„¤μ • λ³µμ΅ | Secondary |
| C | Custom BEV Encoder | μµμ ν™” κ°€λ¥ | κ°λ° μ‹κ°„ | Optional |

## Scope

### In Scope
- μ‹λ®¬λ μ΄μ… Ground Truth μ¶”μ¶ μ‹μ¤ν…
- Pre-trained 3D detection λ¨λΈ ν…μ¤νΈ (MMDetection3D)
- κ°„λ‹¨ν• BEV representation μƒμ„±
- Perception-Planning μΈν„°νμ΄μ¤ μ •μ

### Out of Scope
- 3D Detection λ¨λΈ μμ²΄ ν•™μµ
- LiDAR μ„Έκ·Έλ©ν…μ΄μ…
- Multi-sensor Fusion λ¨λΈ κ°λ°

## Architecture

```
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚                    Phase 3: Perception (Simplified)                  β”‚
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¤
β”‚                                                                      β”‚
β”‚  β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”β”‚
β”‚  β”‚                      INPUT SOURCES                               β”‚β”‚
β”‚  β”‚  β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”         β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”  β”‚β”‚
β”‚  β”‚  β”‚   Simulation     β”‚         β”‚        Real Sensors          β”‚  β”‚β”‚
β”‚  β”‚  β”‚   Ground Truth   β”‚         β”‚   LiDAR   β”‚   Camera         β”‚  β”‚β”‚
β”‚  β”‚  β””β”€β”€β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”€β”         β””β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”΄β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”  β”‚β”‚
β”‚  β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”Όβ”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”Όβ”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”Όβ”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”β”‚
β”‚              β”‚                         β”‚            β”‚                β”‚
β”‚              β–Ό                         β–Ό            β–Ό                β”‚
β”‚  β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”    β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”  β”‚
β”‚  β”‚  Ground Truth Parser  β”‚    β”‚      Pre-trained Detector        β”‚  β”‚
β”‚  β”‚  (Primary Mode)       β”‚    β”‚  (MMDetection3D / OpenPCDet)     β”‚  β”‚
β”‚  β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”    β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”  β”‚
β”‚              β”‚                                β”‚                      β”‚
β”‚              β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”                      β”‚
β”‚                               β–Ό                                      β”‚
β”‚              β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”                      β”‚
β”‚              β”‚      Perception Output         β”‚                      β”‚
β”‚              β”‚  - Detected Objects            β”‚                      β”‚
β”‚              β”‚  - Position, Velocity, Size    β”‚                      β”‚
β”‚              β”‚  - Object Class                β”‚                      β”‚
β”‚              β”‚  - BEV Features (optional)     β”‚                      β”‚
β”‚              β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”                      β”‚
β”‚                               β”‚                                      β”‚
β”‚                               β–Ό                                      β”‚
β”‚              β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”                      β”‚
β”‚              β”‚    β†’ Planning Module (Phase 5) β”‚                      β”‚
β”‚              β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”                      β”‚
β”‚                                                                      β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
```

## Task Breakdown

| ID | Task | Priority | Est. Time |
|----|------|----------|-----------|
| P3-01 | Unity Ground Truth μ¶”μ¶ μ‹μ¤ν… | High | 2μΌ |
| P3-02 | Perception μ¶λ ¥ μΈν„°νμ΄μ¤ μ •μ | High | 1μΌ |
| P3-03 | MMDetection3D ν…μ¤νΈ ν™κ²½ κµ¬μ¶• | Medium | 2μΌ |
| P3-04 | Pre-trained λ¨λΈ μ¶”λ΅  ν…μ¤νΈ | Medium | 2μΌ |
| P3-05 | BEV representation μƒμ„± | Medium | 3μΌ |
| P3-06 | Planning μ—°λ™ μΈν„°νμ΄μ¤ κµ¬ν„ | High | 2μΌ |

## Perception Output Interface

```python
# python/src/models/perception/interface.py

from dataclasses import dataclass
from typing import List
import numpy as np

@dataclass
class DetectedObject:
    """Planning λ¨λ“μ— μ „λ‹¬λλ” κ°μ²΄ μ •λ³΄"""
    object_id: int
    object_class: str  # vehicle, pedestrian, cyclist
    position: np.ndarray  # [x, y, z] in ego frame
    velocity: np.ndarray  # [vx, vy, vz]
    dimensions: np.ndarray  # [length, width, height]
    heading: float  # radians
    confidence: float  # 0.0 - 1.0

@dataclass
class PerceptionOutput:
    """Perception λ¨λ“ μ¶λ ¥"""
    timestamp: float
    objects: List[DetectedObject]
    ego_position: np.ndarray
    ego_velocity: np.ndarray
    bev_features: Optional[np.ndarray] = None  # [H, W, C]
```

## Success Criteria

- [x] Unityμ—μ„ Ground Truth κ°μ²΄ μ •λ³΄ μ¶”μ¶ κ°€λ¥
- [ ] Pre-trained λ¨λΈ μ¶”λ΅  λ™μ‘ ν™•μΈ
- [x] Perception β†’ Planning μΈν„°νμ΄μ¤ λ™μ‘
- [ ] BEV representation μƒμ„± κ°€λ¥
- [x] μ²λ¦¬ μ‹κ°„ < 50ms per frame

**Status: βΈοΈ λ³΄λ¥** - Planning μ§‘μ¤‘ μ „λµμ— λ”°λΌ Ground Truth λ°©μ‹μΌλ΅ μ§„ν–‰ (2026-01-22)

## Timeline

**μμƒ μ†μ”**: 2-3μ£Ό

## Dependencies

- Phase 1 μ™„λ£ (Unity ν™κ²½)
- Phase 2 μ™„λ£ (λ°μ΄ν„° νμ΄ν”„λΌμΈ)
- MMDetection3D μ„¤μΉ
- PyTorch 2.0+

## Pre-trained Models (μ°Έκ³ )

| Model | Dataset | mAP | Inference | Priority |
|-------|---------|-----|-----------|----------|
| PointPillars | nuScenes | 40.1 | 20ms | High |
| CenterPoint | Waymo | 66.8 | 35ms | Medium |
| BEVFusion | nuScenes | 72.9 | 50ms | Low |

## Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| Pre-trained λ¨λΈ νΈν™μ„± | Medium | Medium | Ground Truth μ°μ„  |
| μ¶”λ΅  μ†λ„ λ¶€μ΅± | Low | Low | λ” κ°€λ²Όμ΄ λ¨λΈ μ„ νƒ |
| BEV ν’μ§ λ¬Έμ  | Medium | Medium | λ‹¨μ ν‘ν„ μ‚¬μ© |

## Deliverables

1. **Ground Truth Extractor**: Unityμ—μ„ κ°μ²΄ μ •λ³΄ μ¶”μ¶
2. **Perception Interface**: Planningκ³Όμ ν‘μ¤€ μΈν„°νμ΄μ¤
3. **Pre-trained Model Wrapper**: MMDetection3D λνΌ
4. **BEV Generator**: Bird's Eye View μƒμ„± λ¨λ“
5. **Documentation**: μ‚¬μ© κ°€μ΄λ“ λ° API λ¬Έμ„

---

## π“ Phase μ™„λ£ μ‹: Obsidian μ§€μ‹ν™”

### μ§€μ‹ν™” λ€μƒ
Phase 3 μ™„λ£ ν›„ λ‹¤μ λ‚΄μ©μ„ Obsidian vaultμ— μ •λ¦¬ν•©λ‹λ‹¤:

| μΉ΄ν…κ³ λ¦¬ | λ‚΄μ© |
|----------|------|
| **Ground Truth μ‹μ¤ν…** | Unityμ—μ„ GT μ¶”μ¶ λ°©λ²•, μΆν‘κ³„ λ³€ν™ |
| **Pre-trained λ¨λΈ** | MMDetection3D/OpenPCDet μ‚¬μ©λ²•, μ„±λ¥ λΉ„κµ |
| **BEV ν‘ν„** | BEV μƒμ„± μ•κ³ λ¦¬μ¦, ν•΄μƒλ„/λ²”μ„ μ„¤μ • |
| **μΈν„°νμ΄μ¤ μ„¤κ³„** | Perception β†’ Planning λ°μ΄ν„° νλ¦„ |
| **μ„±λ¥ μµμ ν™”** | μ¶”λ΅  μ†λ„ κ°μ„  κΈ°λ²• |

### μ‹¤ν–‰ λ°©λ²•
```bash
/obsidian sync --phase=3
```

### μƒμ„±λ  λ…ΈνΈ κµ¬μ΅°
```
Obsidian Vault/
β”β”€β”€ Projects/
β”‚   β””β”€β”€ AD-ML-Platform/
β”‚       β”β”€β”€ Phase-3-Perception/
β”‚       β”‚   β”β”€β”€ Ground-Truth-μ¶”μ¶-μ‹μ¤ν….md
β”‚       β”‚   β”β”€β”€ Pre-trained-λ¨λΈ-λΉ„κµ.md
β”‚       β”‚   β”β”€β”€ BEV-Representation.md
β”‚       β”‚   β”β”€β”€ Perception-Planning-μΈν„°νμ΄μ¤.md
β”‚       β”‚   β””β”€β”€ νΈλ¬λΈ”μν…-λ΅κ·Έ.md
β”‚       β””β”€β”€ ...
